% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
\label{chap:intro}
Producing \emph{natural language} comes \emph{natural} primarily to us humans.
The key to computers' versatility and efficiency---their ``language''---are data structures: arrays, lists, trees and graphs, tables and databases.
We can scrutinize the data with appropriate tools---provided we have sufficient domain expertise and amount of time---but this does not address the core of the problem: that to most people, reading structured data is like trying to decipher a foreign language. As the volume of data in our world grows, it is tempting to turn the question on its head: Can we instead teach computers to describe the structured data in our natural language?


The question has been on the table since the dawn of computing. The first trials of producing natural language with a computer date back to the audacious attempts of \emph{translating} between English and Russian in the 1950s \cite{sheridan1955research}. These experiments stirred a lot of excitement and led to a belief that compared to translating, \emph{generating} English sentences with a set of rules will be a more straightforward task. Although in the 1960s, people slowly began to ponder on its difficulties---\citet{yngve1961random} notices \emph{``surprisingly wide linguistic diversity''} when constructing grammar rules for the first ten sentences of a children's book---the overall sentiment was that language generation will soon be solved. The seminal work of \citet{winograd1971procedures} on SHRDLU, a system able to manipulate a block world according to user instructions, only glosses over presenting the state of the world to the user:
\begin{pquotation}{\citealp[p.384]{winograd1971procedures}}
    [R]esponses can be made as complex and varied as we want, since they are created by the programmer, and the program only repeats them.
\end{pquotation}
In other words, spending enough time with programming appropriate rules was considered enough for automating language generation.

Fast forward to the present, the research world is beaming with excitement again: neural \acp{lm} can miraculously produce the long-awaited complex and varied language \cite{radford2019language,brown2020language}. Similarly to other tasks in \ac{ai}---from object recognition \cite{papert1966summer} to self-driving cars \cite{autonomouscars}---the apparent ease of the task for humans has proven deceptive. In the end, it took us fifty years to build tools for generating fluent natural language. To achieve progress, we had to shift our attention from linguistic theories and rule-based systems, re-defining our systems in terms of data-based approaches and generic learning algorithms.

In the preceding decades, automatic \ac{nlg} systems were built using rules and grammars. The goal of \ac{nlg}---which has meanwhile established itself as a standalone scientific discipline, with its journals, conferences, and stable base of researchers \cite{ACLanthologySIGGEN}---was usually rather pragmatic.
The \ac{nlg} works were the works of \emph{engineering}: natural language was simply taken as one of the suitable mediums to present the structured data to the users in an understandable form. From chart captioning systems \cite{mittalDescribingComplexCharts1998} and graph descriptors \cite{sunDomainIndependentSentence2006}, to weather forecast systems \cite{belzAutomaticGenerationWeather2008} and healthcare report generators \cite{portetAutomaticGenerationTextual2009}, the research papers read like \emph{how-to's} for building systems with widely adopted tools. As a result, the \ac{nlg} systems from that time were accurate and reliable, although perhaps too domain-specific and rigid \cite{reiterBuildingAppliedNatural1997,gattSurveyStateArt2018}.


With neural models, \ac{nlp} as a research field has changed, along with \ac{nlg} as one of its subfields. Most notably, these fields have become more experimental. While neural \acp{lm} opened up fascinating possibilities in building end-to-end systems and solving the long-standing issues with fluency and domain-independence \cite{ferreiraNeuralDatatotextGeneration2019,dusekEvaluatingStateoftheartEndtoEnd2020,sharmaInnovationsNeuralDatatotext2022}, working with neural models turned out to be closer to behavioral sciences than engineering \cite{holtzmanGenerativeModelsComplex2023}. As the researchers began to adapt to the change in the paradigm, the issues concerning experimental design and evaluation came to the surface \cite{gehrmannRepairingCrackedFoundation2022}, and the change was perceived as a step back \cite{reiter2020academic}. The shift towards experimental approaches has also created a gap between research and industry; the industry opting for established approaches meeting industrial standards instead of constantly trying new research artifacts \cite{daleNaturalLanguageGeneration2020,daleNavigatingTextGeneration2023}.


Nevertheless, the progressive approach adopted by \ac{nlp} over the past few years has its merits. The general emphasis on open research, inherited from the \ac{ml} field---where publicly releasing papers, code, and models has become commonplace---has allowed everybody to stand on the proverbial shoulders of giants. As people can build on others' code within minutes of being made public, the research is accelerating and getting more distributed. The convergence towards generic approaches has also led to heavy cross-pollination of ideas, making specific solutions easily applicable to other tasks. As such, \ac{nlg} is helping to advance other areas of \ac{nlp} and contribute to general knowledge of the natural language, its production and processing.

Finally, as we gained other ways to generate language than from structured data---summarize and paraphrase texts, continue text segments, generate stories and answers to questions, or describe images and videos---% \cite{Dong2021ASO}
the original field concerned with \textit{generating descriptions of structured data} has gradually adopted the---perhaps more apt---name of \emph{\ac{d2t} generation}.

This thesis is a story about how \acl{d2t} generation and neural \aclp{lm} came together. On the way, it touches various facets of \ac{d2t} generation: from improving the generation in low-resource settings (\autoref{chap:low-res}), evaluating generated texts (\autoref{chap:evaluation}), processing and visualizing data (\autoref{chap:tabgenie}), to interpreting system behavior (\autoref{chap:investigating}). The point of the thesis is that the adoption of neural approaches in \ac{d2t}---although it has not been going exactly smoothly---is driven by the promise that it can help us to solve some long-standing issues.

The thesis also inevitably reflects the shifts in \ac{nlp} between 2020 and 2024: from the early feeble attempts at generating fluent language with small pretrained \acp{lm}, all the way up to dealing with the hype surrounding the \acp{llm}.  Except for the background section (\autoref{chap:background}), the thesis is rather explorative and focuses on specific experiments, but it can hopefully offer pointers to newcomers in the field along with a handful of fruitful ideas.




\section{Motivation}
\label{sec:rq}

The main goal of the thesis is to close the gap outlined in the introduction: turning experimental approaches into reliable and accurate \ac{d2t} generation systems. As a premise, we consider neural \acp{lm}\footnote{For brevity, we will commonly use ``\acp{lm}'' to denote ``neural \acp{lm}'' throughout the work unless stated otherwise.} as a useful tool of producing fluent and natural-sounding text.
% , with the potential to make a difference in \ac{d2t} systems compared to prior approaches. 
However, we do not take it as a one-size-fits-all solution. Instead, we carefully study how to integrate \acp{lm} in \ac{d2t} systems while adhering to all the strict demands on fluency, controllability, and semantic accuracy of the output.

The side goal of the thesis is then to \textit{understand}: understand the data we are dealing with, the outputs we can reasonably expect, and the behavior of neural-based systems in certain conditions. \ac{d2t} generation has several specifics which make it a good subject for this kind of study: its low-resourceness (due to which there are still questions that cannot be answered with scaling the models), the tension between the established rule-based and new-coming neural approaches, and the fact the specific format and size of the data makes it less amenable for being solved with end-to-end systems.

To make the goals more tangible, we will split them into the following research questions, which we will address in the thesis:

\begin{description}
    \item[RQ1] \textbf{In which scenarios are \acp{lm} useful for \ac{d2t} generation?} At first, it is crucial to identify the strong sides of \acp{lm} and get an intuition of where the models can make the most impact. How far can we get with \ac{lm}-only baselines? And are there outcomes that we can get with \acp{lm} that are better than previous approaches?
    \item[RQ2] \textbf{How to efficiently process the structured data with \acp{lm}?} With structured data, we need to deal with the fact that \acp{lm} were pre-trained on modeling plain text, while our data have rich inner structure. To efficiently leverage the knowledge in \acp{lm}---especially in low-resource settings---we need to find the way to transform the data into a suitable input format while keeping the structure (along with other information in the data) intact.
    \item[RQ3] \textbf{How to make \acp{lm}-based systems more controllable?} A neural component introduced in the \ac{d2t} generation system will inevitably make the system less controllable. The question is if we can minimize these issues by building systems out of smaller and simpler components, training the models for more predictable tasks, or producing intermediate outputs that can be manually examined.
    \item[RQ4] \textbf{How to evaluate the outputs of \ac{d2t} generation systems?} Evaluating generated text is a difficult problem, which gets even harder as the quality of the texts starts to approach the human level. Since human evaluation is costly and time-consuming, we study how to build automatic metrics that can be used for system development and evaluation. Particularly, we focus on the most pressing issue in \ac{d2t} generation: the semantic accuracy of the generated texts with respect to the input data.
    \item[RQ5] \textbf{How do the neural \ac{d2t} generation systems behave?} Understanding the abilities and limitations of the systems is crucial for further progress in the field. How does the format of the data influence the outputs of the models? Are \acp{lm} robust enough to replace rule-based approaches? And what are the most important problems to tackle in neural-based \ac{d2t} systems?
\end{description}



\section{Main Contributions}
\label{sec:contributions}


The following are our main contributions, sequentially corresponding to the research questions outlined in the previous section:
\begin{enumerate}
    \item We show that with a very \textbf{simple \ac{lm}-based finetuned baseline}, we can achieve strong results on a shared task of generating texts from a knowledge graph (\autoref{sec:finetuning}). We also point out the advantages and limitations of open \acp{llm} on \ac{d2t} generation in zero-shot settings (\autoref{sec:prompting}).
    \item We show how to \textbf{transform the data to intermediate text-like input} suitable for \acp{lm} using hand-crafted or automatically extracted templates (\Cref{sec:iterative,sec:pipeline,sec:sem-acc}), rule-based \ac{nlg} methods (\autoref{sec:eval-token}), and specialized \acp{lm} (\autoref{sec:describing}). We show that these methods can serve as a basis both for competitive neural-based \ac{d2t} generation systems and for novel \ac{lm}-based evaluation metrics.
    \item We show how we can limit \acp{lm} to the task of improving text fluency and use these \acp{lm} for building \textbf{more controllable \ac{d2t} generation systems} with an iterative approach (\autoref{sec:iterative}) and modular architecture (\autoref{sec:pipeline}). We show that these systems open up a new way of thinking about neural-based \ac{lm} with a different set of trade-offs than rule-based or end-to-end systems.
    \item We develop \textbf{\ac{lm}-based automatic metrics} for evaluating outputs of \ac{d2t} generation systems on the level of data item mentions (\autoref{sec:sem-acc}) and output tokens (\autoref{sec:eval-token}). We show that the metrics achieve strong correlations with human judgment in comparison with other metrics.
    \item We build a \textbf{tool for visualizing} the structured data and model outputs and show how we can unify the format of multiple \ac{d2t} generation dataset for easier processing (\autoref{sec:tabgenie}). Using novel datasets, we also \textbf{study the behaviors of \acp{lm}} across multiple \ac{d2t} tasks, data formats, and domains and evaluate their semantic accuracy (\Cref{sec:prompting,sec:describing}).
\end{enumerate}



\section{Thesis Overview}
\label{sec:overview}

The thesis is organized into the background chapter (\autoref{chap:background}), the content chapters (\Cref{chap:low-res,chap:evaluation,chap:tabgenie,chap:investigating}), and the concluding chapter (\autoref{chap:conclusions}). The \Cref{chap:low-res,chap:evaluation,chap:tabgenie,chap:investigating}, which describe our contributions, are outlined in \autoref{tab:overview}.

\paragraph{Publications} The thesis contains the content of eight publications written by the author of the thesis. Except for the paper \citet{dusekEvaluatingSemanticAccuracy2020}, where the experimental part was done by the author's supervisor, the author of the thesis was the main author of all the publications and executed major part of the work.\footnote{The contributions for publications with multiple authors are detailed in the respective chapters.} The publications---except for the most recent paper \citet{kasnerReferenceBasedMetricsAnalyzing2024}---were published at top-tier \ac{nlp} conferences ACL, EACL and INLG.

\begin{table*}[t]
    \small
    \begin{tabular}{p{0.7cm}p{8.3cm}p{4cm}}
        \toprule
        \textbf{Sec.}         & \textbf{Topic}                                      & \textbf{Publication}                             \\ \midrule
        \multicolumn{3}{l}{\textbf{\autoref{chap:low-res}: Low-Resource Data-to-Text Generation}}                                      \\
        §\ref{sec:finetuning} & \ac{d2t} generation with a finetuned \ac{lm}        & \citet{kasnerTrainHardFinetune2020}              \\
        §\ref{sec:iterative}  & \ac{d2t} generation with an editing  \ac{lm}        & \citet{kasnerDatatoTextGenerationIterative2020}  \\
        §\ref{sec:pipeline}   & \ac{d2t} generation with a pipeline of \acp{lm}     & \citet{kasner2022neural}                         \\ \cdashlinelr{1-3}
        \multicolumn{3}{l}{\textbf{\autoref{chap:evaluation}: Evaluating Generated Texts}}                                             \\
        §\ref{sec:sem-acc}    & Evaluating \ac{d2t} with natural language inference & \citet{dusekEvaluatingSemanticAccuracy2020}      \\
        §\ref{sec:eval-token} & Evaluating token-level accuracy of complex \ac{d2t} & \citet{kasnerTextinContextTokenLevelError2021}   \\ \cdashlinelr{1-3}
        \multicolumn{3}{l}{\textbf{\autoref{chap:tabgenie}: Data Processing and Visualization}}                                        \\
        §\ref{sec:tabgenie}   & \textsc{TabGenie} toolkit for \ac{d2t} datasets     & \citet{kasnerTabGenieToolkitTabletoText2023}     \\ \cdashlinelr{1-3}
        \multicolumn{3}{l}{\textbf{\autoref{chap:investigating}: Investigating Model Capabilities}}                                    \\
        §\ref{sec:describing} & Describing triples in a knowledge graph             & \citet{kasnerMindLabelsDescribing2022}           \\
        §\ref{sec:prompting}  & \ac{d2t} generation with open \acp{llm}             & \citet{kasnerReferenceBasedMetricsAnalyzing2024} \\\bottomrule
    \end{tabular}

    \caption{Overview of the thesis.}
    \label{tab:overview}
\end{table*}