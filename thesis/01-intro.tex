% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
\label{chap:intro}
Producing \emph{natural language} comes \emph{natural} to us, humans.
The key to computers' versatility and efficiency---their ``language''---are data structures: arrays and lists, trees and graphs, tables and databases.
Without appropriate tools, reading structured data is to most people like deciphering a foreign language. What is the best tool to undestand it? The problem lies not just in the unfamiliar format of such data, but in its scale. As the volume of structured data in our world is ever-growing, it becomes rather tempting to turn the question around: Can we instead make the computer translate the data to a language we already understand?

The attempts at generating natural language with a computer date back to the 1950s, when IBM researchers succesfully used a computer for translating between English and Russian \cite{sheridan1955research}. Shortly after, the work of \citet{chomsky1957syntactic} introduced formal grammar, providing a principled way for generating language with a set of rules. These initial successes stirred a lot of excitement; fully automated human-level language generation seemed within reach. In the 1960s, people slowly began to notice its difficulties: for example, \citet{yngve1961random} notes there is ``surprisingly wide linguistic diversity'' when constructing grammar rules for the first ten sentences of a children's book. Still, the field of text generation gained momentum and descriptions of text generation systems started to appear \cite[\emph{inter alia}]{woolley-1969-automatic,meehan-1975-using,mcdonald-1975-framework,wang-1980-computational}. The report on the state of the art in text generation in 1982 predicted that within five years:
\begin{pquotation}{\citealp{mann-1982-text}}
    The resulting system can be expected to create acceptable, effective texts, limited by quality considerations to be about one page in length.\hspace{2cm}
\end{pquotation}
% The seminal work of \citet{winograd1971procedures} on SHRDLU, a system able to manipulate a block world according to user instructions, only glosses over presenting the state of the world to the user:
% \begin{pquotation}{\citealp[p.384]{winograd1971procedures}}
%     Responses can be made as complex and varied as we want, since they are created by the programmer, and the program only repeats them.
% \end{pquotation}
% In other words, spending enough time with programming appropriate rules was considered enough for automating language generation.

Fast forward to the present, and the research community is beaming with excitement again, this time about the unprecedented capabilities of neural \aclp{lm} (\acsp{lm}) in generating fluent texts \cite{radford2019language,brown2020language}. In the end, it took us over fifty years to build such systems. Similarly to other tasks in \ac{ai}, from object recognition \cite{papert1966summer} to self-driving cars \cite{autonomouscars}, the apparent ease of the task for humans has proven deceptive.  To achieve progress, we had to move away from linguistic theories and rule-based systems, re-defining our systems in terms of data-based approaches and generic learning algorithms.

% In the preceding decades, automatic \ac{nlg} systems were built using rules and grammars \cite{reiterBuildingAppliedNatural1997,gattSurveyStateArt2018}. 
\Ac{nlg} has meanwhile established itself as a standalone scientific discipline, with its journals, conferences, and stable base of researchers.\footnote{See the history of SIGGEN meetings: \url{https://aclanthology.org/sigs/siggen/}.} The research in the preceding decades was characterized by using a varied assortment of tools including grammars, formalisms, linguistic theories, and custom components. Combining these tools was understood as necessary for building text generation systems \cite{mann-1982-text,reiterBuildingAppliedNatural1997}. As a result, many systems from that time---from chart captioning systems \cite{mittalDescribingComplexCharts1998} and graph descriptors \cite{sunDomainIndependentSentence2006}, to weather forecast systems \cite{belzAutomaticGenerationWeather2008} and healthcare report generators \cite{portetAutomaticGenerationTextual2009}---were accurate and reliable, but domain-specific and rigid.


With neural models, \ac{nlp} as a research field, along with \ac{nlg} as one of its subfields, has changed dramatically \cite{gururaja2023build,li2023defining}. Most notably, these fields have become more experimental. While neural \acp{lm} opened up fascinating possibilities in building end-to-end systems and solving the long-standing issues with fluency and domain-independence \cite{ferreiraNeuralDatatotextGeneration2019,dusekEvaluatingStateoftheartEndtoEnd2020,sharmaInnovationsNeuralDatatotext2022}, working with neural models turned out to be closer to behavioral sciences than engineering \cite{holtzmanGenerativeModelsComplex2023}. As the researchers began to ``throw'' neural \acp{lm} at all sorts of problems, the issues concerning experimental design and evaluation came to the surface \cite{gehrmannRepairingCrackedFoundation2022}. Due to this, some researchers perceived the change as questionable at the very least \cite{reiter2020academic,gururaja2023build,michael2023nlp}. The shift towards experimental approaches has also created a gap between research and industry; the industry opted for established approaches meeting industrial standards instead of trying new research artifacts \cite{daleNaturalLanguageGeneration2020,daleNavigatingTextGeneration2023}.


Nevertheless, the progressive approach adopted by \ac{nlp} over the past few years turned out to have its merits. The general emphasis on openness, inherited from the \ac{ml} field---where publicly releasing papers, code, and models has become commonplace---has allowed everybody to stand on the proverbial shoulders of giants. Thanks to open-science initiatives such as arXiv.org\footnote{\url{https://arxiv.org/}} or HuggingFace\footnote{\url{https://huggingface.co/}}, research became more accessible to both researchers and the general public. The convergence towards generic approaches has also led to heavy cross-pollination of ideas, making specific solutions easily applicable to other tasks. As such, \ac{nlg} is helping to advance other areas of \ac{nlp} and contribute to general knowledge of the natural language, its production and processing.

Finally, as we gained ways to generate language that do not require starting from structured representations (summarize and paraphrase texts, continue text segments, generate stories and answers to questions, or describe images and videos), % \cite{Dong2021ASO}
the original field concerned with generating descriptions of structured data has adopted the---perhaps more apt---name of \emph{\ac{d2t} generation}.

This thesis tells a story about how \acl{d2t} generation and neural \aclp{lm} came together. On the way, it touches various facets of \ac{d2t} generation: from improving generation in a low-resource setting (\autoref{chap:low-res}), over evaluating generated texts (\autoref{chap:evaluation}), processing and visualizing data (\autoref{chap:tabgenie}), to interpreting system behavior (\autoref{chap:investigating}).
% After giving an overview of the field in the background section (\autoref{chap:background}), the thesis delves into specific experiments, but it can hopefully offer pointers to newcomers in the field along with a handful of fruitful ideas. 
The thesis inevitably reflects the shifts in \ac{nlp} between 2020 and 2024: from the preliminary attempts at generating fluent language with small pretrained \acp{lm}, all the way up to dealing with the hype surrounding the \acp{llm}. The approaches presented in this thesis are primarily motivated by the idea that adopting neural models in \ac{d2t} may help us solve some long-standing issues with flexibility and text fluency, which were out of reach for the best approaches from previous decades.




\section{Motivation}
\label{sec:rq}

The main goal of the thesis is to close the gap outlined in the introduction: turning experimental approaches into reliable and accurate \ac{d2t} generation systems. As a premise, we consider neural \acp{lm}\footnote{For brevity, we will commonly use ``\acp{lm}'' to denote ``neural \acp{lm}'' throughout this work unless stated otherwise.} as a useful tool of producing fluent and natural-sounding text.
% , with the potential to make a difference in \ac{d2t} systems compared to prior approaches. 
However, we do not take neural \acp{lm} as a one-size-fits-all solution. Instead, we carefully study how to integrate \acp{lm} in \ac{d2t} systems while following the strict demands on fluency, controllability, and semantic accuracy of the output.

The side goal of the thesis is then to \textit{understand}: understand the data we are dealing with, the outputs we can reasonably expect, and the behavior of neural-based systems in certain conditions. \ac{d2t} generation has several specifics that make it a good subject for this kind of study: its resource scarcity (due to which there are still questions that cannot be answered by scaling up the models), the tension between the established rule-based and new-coming neural approaches, and the fact that the specific format and size of the data makes it less suitable for end-to-end solutions.

To make the goals more tangible, we split them into the following research questions, which we address further on in the thesis:

\begin{description}
    \item[RQ1\label{rq:1}] \textbf{In which scenarios are \acp{lm} useful for \ac{d2t} generation?} First, it is crucial to identify the strong sides of \acp{lm} and get an intuition of where the models can make the most impact. How far can we get with \ac{lm}-only baselines? And are there outcomes that we can get with \acp{lm} that are better than previous approaches?
    \item[RQ2\label{rq:2}] \textbf{How to efficiently process the structured data with \acp{lm}?} With structured data, we need to deal with the fact that \acp{lm} were pre-trained on modeling plain text only. To efficiently leverage the knowledge in \acp{lm}---especially in low-resource settings---we need to find the way to transform the data into a suitable input format while keeping its structure (along with other information in the data) intact.
    \item[RQ3\label{rq:3}] \textbf{How to make \ac{lm}-based systems more controllable?} A neural component introduced in the \ac{d2t} generation system will inevitably make the system less controllable. The question is if we can minimize these issues by building systems out of smaller and simpler components, training the models for more predictable tasks, or producing intermediate outputs that can be manually examined.
    \item[RQ4\label{rq:4}] \textbf{How to evaluate the outputs of \ac{d2t} generation systems?} Evaluating generated text gets harder as the quality of the texts starts to approach the human level. Since human evaluation is costly and time-consuming, we study how to build automatic metrics that can be used for system development and evaluation. Particularly, we focus on the most pressing issue in \ac{d2t} generation: semantic accuracy of the generated texts with respect to the input data.
    \item[RQ5\label{rq:5}] \textbf{Do \ac{d2t} generation systems generalize to unseen domains and datasets?} \ac{d2t} generation systems are often evaluated on a limited subset of domains and datasets. Investigating how the models perform on unseen domains, multiple datasets, and real-world data would give us better picture of the limitations of the current approaches.

        % Understanding the abilities and limitations of the systems is crucial for further progress in the field. How does the format of the data influence the outputs of the models? Are \acp{lm} robust enough to replace rule-based approaches? And what are the most important problems to tackle in neural-based \ac{d2t} systems?
\end{description}



\section{Main Contributions}
\label{sec:contributions}


The following are our main contributions, following the research questions outlined above:
% \setlist[description]{labelindent=\parindent, leftmargin=0em}

\begin{description}[leftmargin=\widthof{\textbf{Ad RQ1\ \ }}]
    \item[Ad \ref{rq:1}] We show that  with a very \textbf{simple \ac{lm}-based finetuned baseline}, we can achieve strong results on a shared task of generating texts from a knowledge graph (\autoref{sec:finetuning}). We also point out the advantages and limitations of open \acp{llm} on \ac{d2t} generation in zero-shot settings (\autoref{sec:quintd}).
    \item[Ad \ref{rq:2}] We show how to \textbf{transform the data to intermediate text-like input} suitable for \acp{lm} using handcrafted or automatically extracted templates (\Cref{sec:iterative,sec:pipeline,sec:sem-acc}), rule-based \ac{nlg} methods (\autoref{sec:tok-eval}), and specialized \acp{lm} (\autoref{sec:rel2text}). We show that these methods can serve as a basis both for competitive neural-based \ac{d2t} generation systems and for novel \ac{lm}-based evaluation metrics.
    \item[Ad \ref{rq:3}] We show how we can limit \acp{lm} to the task of improving text fluency and use these \acp{lm} for building \textbf{more controllable \ac{d2t} generation systems} with an iterative approach (\autoref{sec:iterative}) and modular architecture (\autoref{sec:pipeline}). We show that these systems open up a new way of thinking about neural-based \ac{lm} with a different set of trade-offs than rule-based or end-to-end systems.
    \item[Ad \ref{rq:4}] We develop \textbf{\ac{lm}-based automatic metrics} for evaluating outputs of \ac{d2t} generation systems on the level of data item mentions (\autoref{sec:sem-acc}) and output tokens (\autoref{sec:tok-eval}). We show that the metrics achieve strong correlations with human judgment in comparison with other metrics.
    \item[Ad \ref{rq:5}] We \textbf{unify the format} of multiple \ac{d2t} generation datasets for easier processing and visualization (\autoref{sec:tabgenie}). Using novel datasets, we also \textbf{evaluate the output quality and semantic accuracy} of \acp{lm} across multiple \ac{d2t} tasks, data formats, and domains (\Cref{sec:quintd,sec:rel2text}).
\end{description}



\section{Thesis Overview}
\label{sec:overview}

The thesis is organized into the background chapter (\autoref{chap:background}), the content chapters (\Cref{chap:low-res,chap:evaluation,chap:tabgenie,chap:investigating}), and the concluding chapter (\autoref{chap:conclusions}).

The \Cref{chap:low-res,chap:evaluation,chap:tabgenie,chap:investigating}, which describe our contributions, are outlined in \autoref{tab:overview}. First, we describe our work on improving \ac{d2t} generation in low-resource scenarios in \autoref{chap:low-res}. We continue with our work on evaluating the semantic accuracy of \ac{d2t} generation in \autoref{chap:evaluation}. In \autoref{chap:tabgenie}, we describe \textsc{TabGenie}, our toolkit for processing and visualization of \ac{d2t} generation datasets. Finally, in \autoref{chap:investigating}, we present our experiments with cross-domain performance of pretrained and large \acp{lm} on \ac{d2t} generation.

\begin{table*}[t]
    \small
    \begin{tabular}{p{0.7cm}p{8.3cm}p{4cm}}
        \toprule
        \textbf{Sec.}         & \textbf{Topic}                                         & \textbf{Publication}                             \\ \midrule
        \multicolumn{3}{l}{\textbf{\autoref{chap:low-res}: Low-Resource Data-to-Text Generation}}                                         \\
        §\ref{sec:finetuning} & \ac{d2t} generation with a finetuned \ac{lm}           & \citet{kasnerTrainHardFinetune2020}              \\
        §\ref{sec:iterative}  & \ac{d2t} generation with an editing  \ac{lm}           & \citet{kasnerDatatoTextGenerationIterative2020}  \\
        §\ref{sec:pipeline}   & \ac{d2t} generation with a pipeline of \acp{lm}        & \citet{kasner2022neural}                         \\ \cdashlinelr{1-3}
        \multicolumn{3}{l}{\textbf{\autoref{chap:evaluation}: Evaluating Generated Texts}}                                                \\
        §\ref{sec:sem-acc}    & Evaluating \ac{d2t} with natural language inference    & \citet{dusekEvaluatingSemanticAccuracy2020}      \\
        §\ref{sec:tok-eval}   & Evaluating token-level accuracy of complex \ac{d2t}    & \citet{kasnerTextinContextTokenLevelError2021}   \\ \cdashlinelr{1-3}
        \multicolumn{3}{l}{\textbf{\autoref{chap:tabgenie}: Data Processing and Visualization}}                                           \\
        §\ref{sec:tabgenie}   & \textsc{TabGenie} toolkit for \ac{d2t} datasets        & \citet{kasnerTabGenieToolkitTabletoText2023}     \\ \cdashlinelr{1-3}
        \multicolumn{3}{l}{\textbf{\autoref{chap:investigating}: Investigating Domain Generalization}}                                    \\
        §\ref{sec:rel2text}   & Describing unseen triples in a knowledge graph         & \citet{kasnerMindLabelsDescribing2022}           \\
        §\ref{sec:quintd}     & \ac{d2t} generation across domains with open \acp{llm} & \citet{kasnerReferenceBasedMetricsAnalyzing2024} \\\bottomrule
    \end{tabular}

    \caption{Overview of the thesis.}
    \label{tab:overview}
\end{table*}

\paragraph{Publications} The thesis includes the content of eight publications written by the author of the thesis. Except for the paper \citet{dusekEvaluatingSemanticAccuracy2020}, where the experimental part was done by the author's supervisor, the author of the thesis was the main author of all the publications and executed major part of the work.\footnote{The contributions for publications with multiple authors are detailed in the respective chapters.} All the publications were (or are to be) published at top-tier \ac{nlp} conferences ACL, EACL and INLG.

