% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
\label{chap:intro}
Producing \emph{natural language} comes \emph{natural} primarily to us, humans.
The key to computers' versatility and efficiency---their ``language''---are data structures: arrays, lists, trees and graphs, tables and databases.
We can scrutinize the data with appropriate tools---provided sufficient domain expertise and amount of time---but this does not address the core of the problem: that to most people, reading structured data is like trying to decipher a foreign language. As the volume of data in our world grows, it is tempting to turn the question on its head: Can we instead teach the computers to describe the structured data in our, natural language?


Answering this question has been on the table since the dawn of computing. The first attempts at producing natural language with a computer date back to the audacious attempts of \emph{translating} between English and Russian in 1950's \cite{sheridan1955research}, which stirred a lot of excitement and lead to a belief that compared to translating, \emph{generating} English sentences with a set of rules will be a simpler task. Although in 1960's, people slowly began to ponder on its difficulties---\citet{yngve1961random} notes even the first ten sentences of a children's book provide \emph{``surprisingly wide linguistic diversity''}---the overall sentiment was that language generation will soon be solved. The seminal work of \citet{winograd1971procedures}, describing in 461 pages the SHRDLU system which manipulates blocks in an imaginary block world according to user instructions, only glosses over presenting the state of the world to the user:
\begin{pquotation}{\citealp[p.384]{winograd1971procedures}}
    [R]esponses can be made as complex and varied as we want, since they are created by the programmer, and the program only repeats them.
\end{pquotation}
In other words, the language generation was considered solved by the fact that in the computer, we can combine any pre-defined outputs with any rules we desire.

Fast forward to the present, the research world is beaming with excitement again: neural \acp{lm} have a suprising ability of producing the long-awaited complex and varied language \cite{radford2019language,brown2020language}. Similarly to other tasks in \ac{ai}---from object recognition \cite{papert1966summer} to self-driving cars \cite{autonomouscars}---the apparent ease of the task for humans has proven deceptive. In the end, ot took us fifty years to build tools for generating fluent language. To make progress, we had to shift our attention from linguistic theories and rule-based systems, re-defining our systems in terms of data-based approaches and generic learning algorithms.

In the preceding decades, automatic \ac{nlg} systems were being built using rules and grammars. The goal of \ac{nlg}---which has meanwhile established itself as a standalone scientific discipline, with its journals, conferences, and stable base of researchers \cite{ACLanthologySIGGEN}---was usually rather pragmatic.
The \ac{nlg} works were the works of \emph{engineering}: natural language was simply taken as one of the suitable mediums to present the structured data to the users in an understandable form. From chart captioning systems \cite{mittalDescribingComplexCharts1998} and graph descriptors \cite{sunDomainIndependentSentence2006}, to weather forecast systems \cite{belzAutomaticGenerationWeather2008} and healthcare report generators \cite{portetAutomaticGenerationTextual2009}, the research papers read like \emph{how-to's} for building robust systems with widely adopted tools. As a result, the \ac{nlg} systems from that time were accurate and reliable, if only a bit too domain-specific and rigid \cite{reiterBuildingAppliedNatural1997,gattSurveyStateArt2018}.


With neural models, \ac{nlp} as a research field, including \ac{nlg} as one of its subfields, has changed. Most notably, it has become more experimental. While neural \acp{lm} opened up fascinating possibilities in building end-to-end systems and solving the long-standing issues with fluency and domain-independence \cite{ferreiraNeuralDatatotextGeneration2019,dusekEvaluatingStateoftheartEndtoEnd2020,sharmaInnovationsNeuralDatatotext2022}, working with neural models turned out to be closer to behavioral sciences than engineering \cite{holtzmanGenerativeModelsComplex2023}. As the researchers began to adapt to the change in the paradigm, the issues with respect to experimental design and evaluation came to surface \cite{gehrmannRepairingCrackedFoundation2022} and the change was percieved as a step back \cite{reiter2020academic}. The shift towards experimental approaches has also created a gap between research and industry; the industry opting for established approaches meeting industrial standards in the ever-changing research landscape
% 
\cite{daleNaturalLanguageGeneration2020,daleNavigatingTextGeneration2023}.


Nevertheless, the progressive approach adopted by \ac{nlp} over the past few years turned out to have its merits. The general emphasis on open research, inherited from the \ac{ml} field---where publicly releasing papers, code, and models has become commonplace---has allowed everybody to stand on the proverbial shoulders of giants. As people can build on others' code within minutes since its publication, the research is accelerating and gathering more observations. The convergence towards generic aproaches has also lead to heavy cross-pollination of ideas, making ideas for specific tasks applicable to other tasks. As such, \ac{nlg} is helping to advance other areas of \ac{nlp} and contribute to general knowledge on natural language, its production and processing.

Finally, as we gained other ways to generate language than from structured data---summarize and paraphrase texts, continue text segments, generate stories and answers to questions, or describe images and videos---% \cite{Dong2021ASO}
the original field concerned with \textit{generating descriptions of structured data} has gradually adopted the---perhaps more apt---name of \emph{\ac{d2t} generation}.

This thesis is a story about how \acl{d2t} generation and neural \aclp{lm} came together. On the way, it touches various facets of \ac{d2t} generation, from improving the generation in low-resource settings (\autoref{chap:low-res}), evaluating generated texts (\autoref{chap:evaluation}), processing and visualizing data (\autoref{chap:tabgenie}), to interpreting system behavior (\autoref{chap:investigating}). The point of the thesis is that the adoption of neural approaches in \ac{d2t}---although it has not been going exactly smoothly---is driven by the promise that it can help us to solve some long-stading issues. The thesis also inevitably reflects the shifts in \ac{nlp} between 2020 and 2024: from the early (and sometimes a bit desperate) attempts at generating fluent language with small pretrained \acp{lm}, all the way up to dealing with the hype surrounding the \acp{llm}.  Far from being a complete survey, the thesis is rather explorative, but it can hopefully offer pointers to newcomers in the field along with a handful of fruitful ideas.










\section{Motivation}
\label{sec:rq}

The main goal of the thesis is to close the gap outlined in the introduction, turning experimental approaches into reliable and accurate \ac{d2t} generation systems. For the premise, we consider neural \acp{lm}\footnote{For brevity, we will use ``\acp{lm}'' to denote ``neural \acp{lm}'' throughout the work unless stated otherwise.} as a tool of producing fluent and natural-sounding text, with the potential to make a difference in \ac{d2t} systems compared to prior approaches. Importantly---instead of considering \acp{lm} as a hammer and everything as a nail---we carefully study how to integrate \acp{lm} in \ac{d2t} systems while adhering to all the strict demands on fluency, controllability, and semantic accuracy of the output.

The side goal of the thesis is then to \textit{understand}: understand the data we are dealing with, the outputs we can reasonably expect, and the behavior of neural-based systems in certain conditions. The approaches presented for \ac{d2t} generation can often be generalized to other tasks, too, even though \ac{d2t} generation has several specifics which makes it a good subject for this kind of study: its low-resourceness (due to which there are still questions that cannot be answered with scaling the models), the tension between established rule-based approaches and the new-coming neural approaches, and the fact that due to the specific format and size of the data, the task is not straightforwardly solvable with end-to-end systems.

To make the aforementioned goals more tangible, we divide them into the following research questions which we are going to address in the thesis:

\begin{description}
    \item[RQ1] \textbf{In which scenarios are \acp{lm} useful for \ac{d2t} generation?} At first, it is crucial to identify the strong sides of \acp{lm} and get an intuition of where the models can make the most impact. How far can we get with \ac{lm}-only baselines? And are there outcome that we can get with \ac{lm} which are better than any previous approaches?
        % At the same time, it is essential to understand their limitations, and be able to employ the \acp{lm} only where it is actually needed.
    \item[RQ2] \textbf{How to efficiently process the structured data with \acp{lm}?} With structured data, we need to deal with the fact that \acp{lm} were pre-trained on modeling plain text, while the data have rich inner structure. In order to efficiently leverage the knowledge in \acp{lm}---especially in low-resource settings---we need to find the way to transform the data into a suitable input format while keeping the structure (along with other information in the data) intact.
    \item[RQ3] \textbf{How to make \acp{lm}-based systems more controllable?} A neural component introduced in the \ac{d2t} generation system will raise issues with controllability. The question is if we can minimize these issues, for example by building systems out of smaller and simpler components, training the models for more predictable tasks, or producing intermediate outputs which can be manually examined.
    \item[RQ4] \textbf{How to evaluate the outputs of \ac{d2t} generation systems?} Evaluating generated text is hard, and it gets even harder as the quality of the texts starts to approach human level. Since human evaluation is costly and time-consuming, we study how to build automatic metrics for researchers and the system developer, focusing on the most pressing issue in \ac{d2t} generation: the semantic accuracy of the generated texts with respect to the input data.
    \item[RQ5] \textbf{How do the neural \ac{d2t} generation systems behave?} Undestanding the abilities and limitations of the systems is crucial both for researchers and for potentional practicioners in the field. Are there tasks which are fundamentally unsolvable with \acp{lm}---or any other approach for that sake---for example because the task is ill-defined? And what are the most imporant problems to solve in neural-based \ac{d2t} systems?
\end{description}



\section{Main Contributions}
\label{sec:contributions}


Our main contributions, sequentially corresponding to the research questions outlined above, are:
\begin{enumerate}
    \item We show that with a very \textbf{simple \ac{lm}-based finetuned baseline}, we can achieve strong results on a shared task of generating texts from a knowledge graph (\autoref{sec:finetuning}). We also point out the advantages and limitations of open \acp{llm} on \ac{d2t} generation in zero-shot settings (\autoref{sec:prompting}).
    \item We show how to \textbf{transform the data to intermediate text-like input} suitable for \acp{lm} using hand-crafted or automatically extracted templates (\Cref{sec:iterative,sec:pipeline,sec:sem-acc}), rule-based \ac{nlg} methods (\autoref{sec:eval-token}), and specialized \acp{lm} (\autoref{sec:describing}). We show that these methods can serve as a basis both for competitive neural-based \ac{d2t} generation systems and for novel \ac{lm}-based evaluation metrics.
    \item We show how we can limit \acp{lm} to the task of improving text fluency, and use these \acp{lm} for building \textbf{more controllable \ac{d2t} generation systems} with either an iterative approach (\autoref{sec:iterative}) or modular architecture (\autoref{sec:pipeline}). We show that these systems open up a new way of thinking about neural-based \ac{lm} with a different set of trade-offs that rule-based or end-to-end systems.
    \item We develop \textbf{\ac{lm}-based automatic metrics} for evaluating outputs of \ac{d2t} generation systems on the level of data item mentions (\autoref{sec:sem-acc}) and output tokens (\autoref{sec:eval-token}). We show that the metrics achieve strong correlations with human judgement in comparison with other metrics.
    \item We build a \textbf{tool for visualizing} the structured data and model outputs and show how we can unify the format of multiple \ac{d2t} generation dataset for easier processing (\autoref{sec:tabgenie}). Using custom datasets, we also \textbf{study the behaviors of \acp{lm}} across multiple \ac{d2t} tasks, data formats, and domains, evaluate the semantic accuracy of \acp{lm}, and provide recommendations for future research in \ac{d2t} generation with \acp{llm} (\Cref{sec:prompting,sec:describing}).
\end{enumerate}



\section{Thesis Overview}
\label{sec:overview}

The thesis is organized into the background chapter (\autoref{chap:background}), four content chapters (\Cref{chap:low-res,chap:evaluation,chap:tabgenie,chap:investigating}), and the concluding chapter (\autoref{chap:conclusions}). The \Cref{chap:low-res,chap:evaluation,chap:tabgenie,chap:investigating}, which describe our contributions, are outlined in \autoref{tab:overview}.

\paragraph{Publications} The thesis contains the content of eight publications written by the author of the thesis. Except for the paper \citet{dusekEvaluatingSemanticAccuracy2020}, where the experimental part was done by the author's supervisor, the author of the thesis was the main author of all the publications and executed major part of the work.\footnote{The contributions for publications with multiple authors are detailed in the respective chapters.} The publications---except for the most recent paper \citet{kasnerReferenceBasedMetricsAnalyzing2024}---were published at top-tier \ac{nlp} conferences ACL, EACL and INLG.

\begin{table*}[t]
    \small
    \begin{tabular}{p{0.7cm}p{8.3cm}p{4cm}}
        \toprule
        \textbf{Sec.}         & \textbf{Topic}                                      & \textbf{Publication}                             \\ \midrule
        \multicolumn{3}{l}{\textbf{\autoref{chap:low-res}: Low-Resource Data-to-Text Generation}}                                      \\
        §\ref{sec:finetuning} & \ac{d2t} generation with a finetuned \ac{lm}        & \citet{kasnerTrainHardFinetune2020}              \\
        §\ref{sec:iterative}  & \ac{d2t} generation with an editing  \ac{lm}        & \citet{kasnerDatatoTextGenerationIterative2020}  \\
        §\ref{sec:pipeline}   & \ac{d2t} generation with a pipeline of \acp{lm}     & \citet{kasner2022neural}                         \\ \cdashlinelr{1-3}
        \multicolumn{3}{l}{\textbf{\autoref{chap:evaluation}: Evaluating Generated Texts}}                                             \\
        §\ref{sec:sem-acc}    & Evaluating \ac{d2t} with natural language inference & \citet{dusekEvaluatingSemanticAccuracy2020}      \\
        §\ref{sec:eval-token} & Evaluating token-level accuracy of complex texts    & \citet{kasnerTextinContextTokenLevelError2021}   \\ \cdashlinelr{1-3}
        \multicolumn{3}{l}{\textbf{\autoref{chap:tabgenie}: Data Processing and Visualization}}                                        \\
        §\ref{sec:tabgenie}   & \textsc{TabGenie}: A toolkit for \ac{d2t} datasets  & \citet{kasnerTabGenieToolkitTabletoText2023}     \\ \cdashlinelr{1-3}
        \multicolumn{3}{l}{\textbf{\autoref{chap:investigating}: Investigating Model Capabilities}}                                    \\
        §\ref{sec:describing} & Describing triples in a knowledge graph             & \citet{kasnerMindLabelsDescribing2022}           \\
        §\ref{sec:prompting}  & \ac{d2t} generation with open \acp{llm}             & \citet{kasnerReferenceBasedMetricsAnalyzing2024} \\\bottomrule
    \end{tabular}

    \caption{Overview of the thesis.}
    \label{tab:overview}
\end{table*}