%%% The main file. It contains definitions of basic parameters and includes all other parts.

%% Settings for single-side (simplex) printing
% Margins: left 40mm, right 25mm, top and bottom 25mm
% (but beware, LaTeX adds 1in implicitly)
\documentclass[12pt,notitlepage,a4paper,openright]{report}
\pagestyle{plain}

\PassOptionsToPackage{hyperfootnotes=false}{hyperref}

% fix pdfx
\usepackage{etoolbox}
% \makeatletter
% \@ifl@t@r\fmtversion{2021-06-01}%
%  {\AddToHook{package/after/xmpincl}
%    {\patchcmd\mcs@xmpincl@patchFile{\if\par}{\ifx\par}{}{\fail}}}{}
% \makeatother

\usepackage[usenames,dvipsnames,svgnames,table,rgb]{xcolor}
\usepackage[a-2u]{pdfx}
\usepackage{fontspec}
\usepackage[czech,english]{babel}
\usepackage{lmodern}
\usepackage{textcomp}
\usepackage[defaultlines=4,all]{nowidow}

% Turn this on when needed:
%\usepackage{microtype}

\usepackage{graphicx}
\usepackage[twoside, inner=3.7cm, outer=2.9cm, top=2.6cm, bottom=3.4cm]{geometry}
\usepackage{thesis}
\usepackage[round]{natbib}
\usepackage{multirow}
\usepackage{arydshln} % dashed lines in tables
\usepackage{array}
\usepackage{amssymb,latexsym,pifont}
\usepackage{amsmath}
\usepackage{enumitem} % custom lists
\usepackage[normalem]{ulem} % underlining
\usepackage{setspace} % line spacing
\usepackage{varioref} % nice references (above/below)
\usepackage[above,section]{placeins} % avoid figures pushed at end of chapters
\usepackage{listings}

\usepackage{tabularx}
\usepackage{booktabs} % nicer lines in table
\usepackage{multicol}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usepackage{gnuplot-lua-tikz}
\usetikzlibrary{shapes.geometric}
\usepackage{epstopdf}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}
\usepackage{quoting,xparse}

% acronyms and glossaries
\usepackage[acronym, nomain]{glossaries}
\usepackage[shortcuts=ac]{glossaries-extra}
\makeglossaries
\preto\chapter{\glsresetall}

\setabbreviationstyle[acronym]{long-short}

\usepackage{subcaption} % sub figures in a fiture
\usepackage{standalone} % include standoalone tikz images
\usepackage{bibentry}

% hack bibentry command for list of publications
\makeatletter
\renewcommand\bibentry[1]{\nocite{#1}{\frenchspacing
     \@nameuse{BR@r@#1\@extra@b@citeb}}}
\makeatother


\definecolor{mydarkblue}{rgb}{0,0.08,0.45}
\hypersetup{ %
  colorlinks=true,
  linkcolor=mydarkblue,
  citecolor=mydarkblue,
  filecolor=mydarkblue,
  urlcolor=mydarkblue,
}
\renewcommand{\sectionautorefname}{Section}
\renewcommand{\subsectionautorefname}{Section}
\renewcommand{\subsubsectionautorefname}{Section}

% \hypersetup{
%     colorlinks=false,
%     pdfborder={0 0 0},
%     unicode=true,
% }

\input{acronyms}

% Czech babel conflicts with cline, hacky fix (http://tex.stackexchange.com/questions/111999/slovak-and-czech-babel-gives-problems-with-cmidrule-and-cline):
% - basically disables hyphenation in tables, but it's not used anyway so it doesn't matter
\preto\tabular{\shorthandoff{-}}
\preto\tikzpicture{\shorthandoff{-}}
%
%
\hyphenation{%
da-ta-sets
da-ta-set
} % -- custom hyphenation

\setmainfont[Ligatures=Common]{Libertinus Serif}
% \setmainfont[Ligatures=Common]{Linux Libertine O}
\setsansfont[Scale=MatchLowercase]{DejaVu Sans}
\setmonofont[Scale=MatchLowercase]{DejaVu Sans Mono}


\NewDocumentCommand{\bywhom}{m}{% the Bourbaki trick
  {\nobreak\hfill\penalty50\hskip1em\null\nobreak
   \hfill\mbox{\normalfont(#1)}%
   \parfillskip=0pt \finalhyphendemerits=0 \par}%
}

\NewDocumentEnvironment{pquotation}{m}
  {\begin{quoting}[
     indentfirst=true,
     leftmargin=\parindent,
     rightmargin=\parindent]\itshape}
  {\bywhom{#1}\end{quoting}}

\setstretch{1.1} % line spacing

\expandafter\def\expandafter\quote\expandafter{\quote\small} % smaller quotations font


% orphan & widow control
%\clubpenalty 10000
%\widowpenalty 10000

% gaps between text and footnotes
\def\footnoteskip#1{
  \renewcommand\footnoterule{
     \vspace{#1}
     \hrule width 0.4\columnwidth%
     \vspace{3pt}
}
}
\footnoteskip{0.8em}


\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{2}

%% cutting down warnings
%\hfuzz=2pt
%\hbadness=10000

% force-ordering citations according to dummy keys
\newcommand{\dummybiborderkey}[1]{}

\input{macros}

\newcommand{\veryshortarrow}[1][3pt]{\mathrel{%
     \vcenter{\hbox{\rule[-.5\fontdimen8\textfont3]{#1}{\fontdimen8\textfont3}}}%
     \mkern-4mu\hbox{\usefont{U}{lasy}{m}{n}\symbol{41}}}}

\newcommand{\paperdisclaim}[1]{%
\begin{center}\begin{minipage}{0.9\textwidth}
\footnotesize\it #1
\end{minipage}\end{center}
}

\def\ignorecolumn#1\unskip{}

\title{Data-to-Text Generation with Neural Language Models}
% \title{Techniques for Neural Data-to-Text Generation}

\def\fulldate{}
\author{Zdeněk Kasner}
\date{2024}
\dept{Institute of Formal and Applied Linguistics}
\supervisor{Mgr. et Mgr. Ondřej Dušek, Ph.D.}
\studyprogram{Computer Science}
\studyfield{Computational Linguistics}


\begin{document}

%
%
%
\renewcommand{\thepage}{\roman{page}}
\renewcommand\cite{\citep}
\selectlanguage{english}
\maketitle

\pagestyle{plain}
\normalsize
\setcounter{page}{2}

\cleardoublepage{}
\ \vspace{10mm}

\noindent \it

\vspace{\fill}
\noindent \rm
I declare that I carried out this doctoral thesis independently,
and only with the cited sources, literature and other professional sources.

I understand that my work relates to the rights and obligations
under the Act No.~121/2000 Coll., the Copyright Act, as amended,
in particular the fact that Charles University has the right
to conclude a license agreement on the use of this work as a school work
pursuant to Section~60 paragraph~1 of the Copyright Act.

\vspace{2cm}
\noindent Prague, \today \hspace{\fill}\theauthor % doplňte patřičné
% datum, jméno a
% příjmení

%%%   Do not forget to SIGN the printed book here!
%%%                  *********


\cleardoublepage{} % new page
\pagestyle{plain}

\addcontentsline{toc}{chapter}{English Abstract}

%\selectlanguage{english}
\begin{description}[leftmargin=7.5em,labelwidth=7em,labelindent=0em,labelsep=0.5em]
  \item[Title:] \thetitle{}
  \item[Author:] \theauthor{}
  \item[Department:] \thedept{}
  \item[Supervisor:] \thesupervisor{},\\ \thedept{}
\end{description}
\subsubsection{Abstract:}

\input{abstract_en}

\begin{description}[leftmargin=7.5em,labelwidth=7em,labelindent=0em,labelsep=0.5em]
  %
  \item[Keywords:] TODO
    %
\end{description}


\cleardoublepage{}
\addcontentsline{toc}{chapter}{Czech Abstract}
\selectlanguage{czech}
\begin{description}[leftmargin=7.5em,labelwidth=7em,labelindent=0em,labelsep=0.5em]
  \item[Název práce:] TODO
  \item[Autor:] \theauthor{}
  \item[Katedra:] Ústav formální a aplikované lingvistiky
  \item[Vedoucí práce:] \thesupervisor,\\ Ústav formální a aplikované lingvistiky
\end{description}

\subsubsection{Abstrakt:}

\input{abstract_cs}

\begin{description}[leftmargin=7.5em,labelwidth=7em,labelindent=0em,labelsep=0.5em]
  %
  \item[Klíčová slova:] TODO
    %
\end{description}

\selectlanguage{english}




\cleardoublepage{}
\ \vspace{10mm}

\addcontentsline{toc}{chapter}{Acknowledgements}
\subsection*{Acknowledgements}

{

  TODO
  % Here, you can thank anyone and say anything.

  %   \vspace{1\baselineskip}
  %   \noindent
  %   This is how I separated different kinds of thank-yous.

  %   \vspace{1\baselineskip}
  %   \noindent
  %   ... continued. 
}

\vfill


{\noindent\footnotesize %
  This work has been using language resources and tools developed and/or stored and/or distributed by the  LINDAT/CLARIN project of the Ministry of Education, Youth and Sports of the Czech Republic (project LM2015071).
}

\cleardoublepage{}
\addcontentsline{toc}{chapter}{Table of Contents}
\tableofcontents % automatically generated

\cleardoublepage{}
\renewcommand{\chapterheadstartvskip}{\vspace*{-10mm}} % chapter spacing
\setstretch{1.2} % line spacing

%
% TEXT START
%
\renewcommand{\thepage}{\arabic{page}}
\setcounter{page}{1}




\sloppy
% \include{01-intro}
% \include{02-method}
% \include{03-conclusions}

\chapter{Introduction}
\label{chap:intro}
Producing \textit{natural language} is \textit{natural} only to humans, to computers less so. The key to computers' versatility and efficiency -- their ``language'' -- are data structures: arrays, lists, trees and graphs, tables and databases. Once the data stored in these structures meets human eyes, it is vital that humans are able to understand and interpret it. Do we need domain experts to scrutinize over these structures, or can we hope to teach the computers to translate the data into our language?

The answer seems to be in favor of the latter. After all, the first attempts at producing language with computers date back to the dawn of computing, with audacious attempts of \textit{translating} between English and Russian in 1950's \cite{sheridan1955research}. With all the initial excitement, \textit{generating} English-only sentences seemed like a simpler task. Although in 1960's, people slowly began to ponder on the difficulties of generating language---\citet{yngve1961random} notes that creating grammar rules for a simple children's book is difficult since even the first ten sentences provide \textit{``surprisingly wide linguistic diversity''}---the overall sentiment was that language generation will soon be solved up to some minor details. The 461-page seminal work of \citet{winograd1971procedures} on SHRDLU, a system which can manipulate blocks according to user instructions, only glosses over presenting the state of the block world to the user:
\begin{pquotation}{\citealp[p.384]{winograd1971procedures}}
  [R]esponses can be made as complex and varied as we want, since they are created by the programmer, and the program only repeats them.
\end{pquotation}
Skipping ahead 50 years of research (to which we will return in detail in \autoref{sec:rule-d2t}), the research world beams with excitement again: neural \acp{lm} are now able to generate the long-sought \textit{complex} and \textit{varied} language. Similarly to other ideas in artificial intelligence---from object recognition \cite{papert1966summer} to self-driving cars \cite{autonomouscars}---the apparent ease of the task for humans has proven deceptive. To make progress, we needed to shift our attention linguistic theories and rule-based systems, re-defining our approach in terms of data-based approaches and generic learning algorithms.

Over the past decades, the goal of most of the \ac{nlg} systems turned out to be rather pragmatic: taking data from a particular system  and presenting them to the users in the form they will understand. The works in \ac{nlg} were the works in \textit{engineering}, striving to craft systems using well-understood tools to achieve particular results. Natural language, as one of the suitable mediums to describe the data in the computer, was used to present the data from healthcare, to weather forecasts and sport reports. The \ac{nlg} systems built until the arrival of neural models were accurate and reliable, if only a bit too domain-specific and rigid \cite{reiterBuildingAppliedNatural1997,gattSurveyStateArt2018}. The essence of these systems was transforming a non-linguistic inputs to linguistic outputs according to a sequence of rule. In some sense, we can therefore say that transforming data to text---what is now specifically called \ac{d2t} generation---was all there was to \ac{nlg}.

With neural models, the approaches to \glsxtrfull{d2t} generation are getting more experimental and help to advance the \glsxtrfull{nlp} in general.


% Data-to-text generation is the process of starting with the textual representation understandable to computers and ending up the the  textual representation undestandable to humans.

\section{Research Questions}
\label{sec:rq}
\section{Main Contributions}
\label{sec:contributions}
\section{Thesis Overview}
\label{sec:overview}

\chapter{Background}
\label{chap:background}
\section{Neural Language Models}
\label{sec:lms}
\subsection{Neural Networks}
\label{sec:nns}
\subsection{Transformer Architecture}
\label{sec:transformer}
\subsection{Pretrained Language Models}
\label{sec:plms}
\subsection{Large Language Models}
\label{sec:llms}
\section{Data-to-Text Generation}
\label{sec:d2t}
\subsection{Rule-based Approaches}
\label{sec:rule-d2t}
\subsection{Neural Approaches}
\label{sec:neural-d2t}
\subsection{Datasets}
\label{sec:datasets}
\subsection{Evaluation Metrics}
\label{sec:evaluation}

\chapter{Low-Resource Data-to-Text Generation}
\label{chap:low-res}
\section{Motivation}
\label{sec:low-res-mot}
\section{Finetuning LMs}
\label{sec:finetuning}
\subsection{WebNLG+ Shared Task}
\label{sec:webnlgp}
\subsection{Our Submission}
\label{sec:mbart}
\section{Iterative Template Fusion with Text-Editing LMs}
\label{sec:iterative}
\subsection{Text-Editing LMs}
\label{sec:text-editing}
\subsection{Experiments}
\label{sec:text-editing-exp}
\section{Pipelined Text-Based Operations with Pretrained LMs}
\label{sec:pipeline}
\subsection{Pipeline Operations}
\label{sec:pipeline-ops}
\subsection{Experiments}
\label{sec:pipeline-exp}

\chapter{Evaluating Generated Text}
\label{chap:evaluation}
\section{Motivation}
\label{sec:evalution-mot}
\section{Evaluating Semantic Accuracy}
\label{sec:sem-acc}
\subsection{Experiments}
\label{sec:sem-acc-exp}
\section{Token-Level Error Detection}
\label{sec:eval-token}
\subsection{Shared Task}
\label{sec:eval-st}
\subsection{Our Submission}
\label{sec:eval-ours}

\chapter{Data Processing and Visualization}
\label{chap:data}
\section{Motivation}
\label{sec:data-mot}
\section{TabGenie Toolkit}
\label{sec:tabgenie}
\subsection{Data Processing}
\label{sec:tabgenie-data}
\subsection{Web Interface}
\label{sec:tabgenie-web}
\subsection{Programming Interface}
\label{sec:tabgenie-cli}


\chapter{Investigating Model Capabilities}
\label{chap:investigating}
\section{Motivation}
\label{sec:investigating-mot}
\section{Describing Triples in Knowledge Graphs}
\label{sec:describing}
\subsection{Knowledge Graphs}
\label{sec:kgs}
\subsection{Rel2Text Dataset}
\label{sec:rel2text}
\subsection{Experiments}
\label{sec:rel2text-exp}
\section{Prompting Open LLMs}
\label{sec:prompting}
\subsection{\textsc{Quintd} Toolkit}
\label{sec:quintd}
\subsection{Experiments}
\label{sec:quintd-exp}




\chapter{Conclusions}
\label{chap:conclusions}


%
% TEXT END
%

\renewcommand{\chapterheadstartvskip}{\vspace*{0mm}} % chapter spacing

\cleardoublepage{}
\bibliographystyle{csplainnat}
\addcontentsline{toc}{chapter}{Bibliography}
{\small \bibliography{references}}

\cleardoublepage{}
\addcontentsline{toc}{chapter}{List of Abbreviations}
\renewcommand*{\acronymname}{List of Abbreviations}
\printglossary[type=\acronymtype,style=index]

\addcontentsline{toc}{chapter}{List of Tables}
{\small \listoftables\par}

\addcontentsline{toc}{chapter}{List of Figures}
{\small \listoffigures\par}

\cleardoublepage{}
\addcontentsline{toc}{chapter}{List of Publications}
\include{list_of_publications}

\end{document}
