%%% The main file. It contains definitions of basic parameters and includes all other parts.

%% Settings for single-side (simplex) printing
% Margins: left 40mm, right 25mm, top and bottom 25mm
% (but beware, LaTeX adds 1in implicitly)
\documentclass[12pt,notitlepage,a4paper,openright]{report}
\pagestyle{plain}

\PassOptionsToPackage{hyperfootnotes=false}{hyperref}

% fix pdfx
\usepackage{etoolbox}
% \makeatletter
% \@ifl@t@r\fmtversion{2021-06-01}%
%  {\AddToHook{package/after/xmpincl}
%    {\patchcmd\mcs@xmpincl@patchFile{\if\par}{\ifx\par}{}{\fail}}}{}
% \makeatother

\usepackage[usenames,dvipsnames,svgnames,table,rgb]{xcolor}
\usepackage[a-2u]{pdfx}
\usepackage{fontspec}
\usepackage[czech,english]{babel}
\usepackage{lmodern}
\usepackage{textcomp}
\usepackage[defaultlines=4,all]{nowidow}

% Turn this on when needed:
%\usepackage{microtype}

\usepackage{graphicx}
\usepackage[twoside, inner=3.7cm, outer=2.9cm, top=2.6cm, bottom=3.4cm]{geometry}
\usepackage{thesis}
\usepackage[round]{natbib}
\usepackage{multirow}
\usepackage{arydshln} % dashed lines in tables
\usepackage{array}
\usepackage{amssymb,latexsym,pifont}
\usepackage{amsmath}
\usepackage{enumitem} % custom lists
\usepackage[normalem]{ulem} % underlining
\usepackage{setspace} % line spacing
\usepackage{varioref} % nice references (above/below)
\usepackage[above,section]{placeins} % avoid figures pushed at end of chapters
\usepackage{listings}

\usepackage{tabularx}
\usepackage{booktabs} % nicer lines in table
\usepackage{multicol}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usepackage{gnuplot-lua-tikz}
\usetikzlibrary{shapes.geometric}
\usepackage{epstopdf}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}

% acronyms and glossaries
\usepackage[acronym, nomain]{glossaries}
\usepackage[shortcuts=ac]{glossaries-extra}
\makeglossaries
\preto\chapter{\glsresetall}

\setabbreviationstyle[acronym]{long-short}

\usepackage{subcaption} % sub figures in a fiture
\usepackage{standalone} % include standoalone tikz images
\usepackage{bibentry}

% hack bibentry command for list of publications
\makeatletter
\renewcommand\bibentry[1]{\nocite{#1}{\frenchspacing
     \@nameuse{BR@r@#1\@extra@b@citeb}}}
\makeatother


\definecolor{mydarkblue}{rgb}{0,0.08,0.45}
\hypersetup{ %
  colorlinks=true,
  linkcolor=mydarkblue,
  citecolor=mydarkblue,
  filecolor=mydarkblue,
  urlcolor=mydarkblue,
}

% \hypersetup{
%     colorlinks=false,
%     pdfborder={0 0 0},
%     unicode=true,
% }

\input{acronyms}

% Czech babel conflicts with cline, hacky fix (http://tex.stackexchange.com/questions/111999/slovak-and-czech-babel-gives-problems-with-cmidrule-and-cline):
% - basically disables hyphenation in tables, but it's not used anyway so it doesn't matter
\preto\tabular{\shorthandoff{-}}
\preto\tikzpicture{\shorthandoff{-}}
%
%
\hyphenation{%
da-ta-sets
da-ta-set
} % -- custom hyphenation

\setmainfont[Ligatures=Common]{Libertinus Serif}
% \setmainfont[Ligatures=Common]{Linux Libertine O}
\setsansfont[Scale=MatchLowercase]{DejaVu Sans}
\setmonofont[Scale=MatchLowercase]{DejaVu Sans Mono}


\setstretch{1.1} % line spacing

\expandafter\def\expandafter\quote\expandafter{\quote\small} % smaller quotations font

% orphan & widow control
%\clubpenalty 10000
%\widowpenalty 10000

% gaps between text and footnotes
\def\footnoteskip#1{
  \renewcommand\footnoterule{
     \vspace{#1}
     \hrule width 0.4\columnwidth%
     \vspace{3pt}
}
}
\footnoteskip{0.8em}


\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{2}

%% cutting down warnings
%\hfuzz=2pt
%\hbadness=10000

% force-ordering citations according to dummy keys
\newcommand{\dummybiborderkey}[1]{}

\input{macros}

\newcommand{\veryshortarrow}[1][3pt]{\mathrel{%
     \vcenter{\hbox{\rule[-.5\fontdimen8\textfont3]{#1}{\fontdimen8\textfont3}}}%
     \mkern-4mu\hbox{\usefont{U}{lasy}{m}{n}\symbol{41}}}}

\newcommand{\paperdisclaim}[1]{%
\begin{center}\begin{minipage}{0.9\textwidth}
\footnotesize\it #1
\end{minipage}\end{center}
}

\def\ignorecolumn#1\unskip{}

\title{Data-to-Text Generation with Neural Language Models}
% \title{Techniques for Neural Data-to-Text Generation}

\def\fulldate{}
\author{Zdeněk Kasner}
\date{2024}
\dept{Institute of Formal and Applied Linguistics}
\supervisor{Mgr. et Mgr. Ondřej Dušek, Ph.D.}
\studyprogram{Computer Science}
\studyfield{Computational Linguistics}


\begin{document}

%
%
%
\renewcommand{\thepage}{\roman{page}}
\renewcommand\cite{\citep}
\selectlanguage{english}
\maketitle

\pagestyle{plain}
\normalsize
\setcounter{page}{2}

\cleardoublepage{}
\ \vspace{10mm}

\noindent \it

\vspace{\fill}
\noindent \rm
I declare that I carried out this doctoral thesis independently,
and only with the cited sources, literature and other professional sources.

I understand that my work relates to the rights and obligations
under the Act No.~121/2000 Coll., the Copyright Act, as amended,
in particular the fact that Charles University has the right
to conclude a license agreement on the use of this work as a school work
pursuant to Section~60 paragraph~1 of the Copyright Act.

\vspace{2cm}
\noindent Prague, \today \hspace{\fill}\theauthor % doplňte patřičné
% datum, jméno a
% příjmení

%%%   Do not forget to SIGN the printed book here!
%%%                  *********


\cleardoublepage{} % new page
\pagestyle{plain}

\addcontentsline{toc}{chapter}{English Abstract}

%\selectlanguage{english}
\begin{description}[leftmargin=7.5em,labelwidth=7em,labelindent=0em,labelsep=0.5em]
  \item[Title:] \thetitle{}
  \item[Author:] \theauthor{}
  \item[Department:] \thedept{}
  \item[Supervisor:] \thesupervisor{},\\ \thedept{}
\end{description}
\subsubsection{Abstract:}

\input{abstract_en}

\begin{description}[leftmargin=7.5em,labelwidth=7em,labelindent=0em,labelsep=0.5em]
  %
  \item[Keywords:] TODO
    %
\end{description}


\cleardoublepage{}
\addcontentsline{toc}{chapter}{Czech Abstract}
\selectlanguage{czech}
\begin{description}[leftmargin=7.5em,labelwidth=7em,labelindent=0em,labelsep=0.5em]
  \item[Název práce:] TODO
  \item[Autor:] \theauthor{}
  \item[Katedra:] Ústav formální a aplikované lingvistiky
  \item[Vedoucí práce:] \thesupervisor,\\ Ústav formální a aplikované lingvistiky
\end{description}

\subsubsection{Abstrakt:}

\input{abstract_cs}

\begin{description}[leftmargin=7.5em,labelwidth=7em,labelindent=0em,labelsep=0.5em]
  %
  \item[Klíčová slova:] TODO
    %
\end{description}

\selectlanguage{english}




\cleardoublepage{}
\ \vspace{10mm}

\addcontentsline{toc}{chapter}{Acknowledgements}
\subsection*{Acknowledgements}

{

  TODO
  % Here, you can thank anyone and say anything.

  %   \vspace{1\baselineskip}
  %   \noindent
  %   This is how I separated different kinds of thank-yous.

  %   \vspace{1\baselineskip}
  %   \noindent
  %   ... continued. 
}

\vfill


{\noindent\footnotesize %
  This work has been using language resources and tools developed and/or stored and/or distributed by the  LINDAT/CLARIN project of the Ministry of Education, Youth and Sports of the Czech Republic (project LM2015071).
}

\cleardoublepage{}
\addcontentsline{toc}{chapter}{Table of Contents}
\tableofcontents % automatically generated

\cleardoublepage{}
\renewcommand{\chapterheadstartvskip}{\vspace*{-10mm}} % chapter spacing
\setstretch{1.2} % line spacing

%
% TEXT START
%
\renewcommand{\thepage}{\arabic{page}}
\setcounter{page}{1}




\sloppy
% \include{01-intro}
% \include{02-method}
% \include{03-conclusions}

\chapter{Introduction}
The key to computers' versatility and efficiency -- their ``language'' -- is processing, producing, and storing structured data: arrays, lists, tree- and graph-like structures, tables and databases. Producing \textit{natural language} is in fact \textit{natural} only to humans, and to the computers less so. Once the output is computed and eventually meets human eyes,  it needs to be understood and interpreted. Should we thus learn to understand the structured data, or should we teach the computers to translate the data into our language?

The answer seems to be in favor of the latter.
% From the early days of computing, there were attempts to produce output in natural language. 
In fact, after the first audacious attempts of computers \textit{translating} between English and Russian from 1950's \cite{sheridan1955research}, \textit{generating} English-only sentences based on the computer state seemed like an arguably simpler task. To take one example, the seminal work from \citet{winograd1971procedures} on SHRDLU, a system which can manipulate blocks according to natural language instructions, spending over 300 pages on achieving natural language understanding, only glosses over language generation, for which the reasoning goes like following:
\begin{quote}
  \textit{[R]esponses can be made as complex and varied as we want, since they are created by the programmer, and the program only repeats them.} \cite[p.384]{winograd1971procedures}
\end{quote}

Similarly to other ideas in artificial intelligence -- from object recognition \cite{papert1966summer} to self-driving cars \cite{autonomouscars} -- the apparent ease of the task for humans has proven deceptive. Skipping more than 50 years ahead, the neural \glsxtrfullpl{lm} based on the Transformer architecture \cite{vaswani2017attention} are only now starting to provide the long-sought solutions for making the computer generating \textit{complex} and \textit{varied} language. Behind us are decades of works on trying to build fluent, accurate and reliable \glsxtrfull{nlg} systems \cite{reiterBuildingAppliedNatural1997,gattSurveyStateArt2018}.

Over the years, the goal of most of the \acrshort{nlg} systems was rather pragmatic: presenting data to the users in the form they will understand. Natural language, as one of the suitable mediums to describe the data in the computer (along with data visualizations), was used to present the data from weather forecasts to sport reports. In fact, data-to-text generation was all there was to \acrshort{nlg}, (perhaps along with machine translation in the broader sense).

With neural models, the approaches to \glsxtrfull{d2t} generation are getting more experimental and help to advance the \glsxtrfull{nlp} in general.


% Data-to-text generation is the process of starting with the textual representation understandable to computers and ending up the the  textual representation undestandable to humans.

\section{Research Questions}
\section{Main Contributions}
\section{Thesis Overview}

\chapter{Background}
\section{Neural Language Models}
\subsection{Neural Networks}
\subsection{Transformer Architecture}
\section{Pretrained Language Models}
\subsection{Large Language Models}
\section{Data-to-Text Generation}
\subsection{Pipeline-based Approaches}
\subsection{Neural Approaches}
\subsection{Datasets}
\section{NLG Evaluation}
\subsection{Classical Metrics}
\subsection{Model-based Metrics}

\chapter{Low-Resource Data-to-Text Generation}
\section{Motivation}
\section{Finetuning LMs}
\subsection{WebNLG+ Shared Task}
\subsection{Our Submission}
\section{Iterative Template Fusion with Text-Editing LMs}
\subsection{Text-Editing LMs}
\subsection{Experiments}
\section{Pipelined Text-Based Operations with Pretrained LMs}
\subsection{Pipeline Operations}
\subsection{Experiments}
% \section{Zero-shot Prompting with LLMs}

\chapter{Evaluating Generated Text}
\section{Motivation}
\section{Evaluating Semantic Accuracy}
\subsection{Experiments}
\section{Token-Level Error Detection}
\subsection{Shared Task}
\subsection{Our Submission}

\chapter{Data Processing and Visualization}
\section{Motivation}
\section{TabGenie Toolkit}
\subsection{Data Processing}
\subsection{Web Interface}
\subsection{Programming Interface}


\chapter{Investigating Model Capabilities}
\section{Motivation}
\section{Describing Triples in Knowledge Graphs}
\subsection{Knowledge Graphs}
\subsection{Rel2Text Dataset}
\subsection{Experiments}
\section{Prompting Open LLMs}
\subsection{\textsc{Quintd} Toolkit}
\subsection{Experiments}




\chapter{Conclusions}


%
% TEXT END
%

\renewcommand{\chapterheadstartvskip}{\vspace*{0mm}} % chapter spacing

\cleardoublepage{}
\bibliographystyle{csplainnat}
\addcontentsline{toc}{chapter}{Bibliography}
{\small \bibliography{references}}

\cleardoublepage{}
\addcontentsline{toc}{chapter}{List of Abbreviations}
\renewcommand*{\acronymname}{List of Abbreviations}
\printglossary[type=\acronymtype,style=index]

\addcontentsline{toc}{chapter}{List of Tables}
{\small \listoftables\par}

\addcontentsline{toc}{chapter}{List of Figures}
{\small \listoffigures\par}

\cleardoublepage{}
\addcontentsline{toc}{chapter}{List of Publications}
\include{list_of_publications}

\end{document}
