
\chapter{Unified Data Processing}
\label{chap:tabgenie}

In this chapter, we introduce a single set of experiments in \autoref{sec:tabgenie}: an approach for unified processing of \ac{d2t} generation datasets. We first convert the input data in sixteen \ac{d2t} generation datasets of various formats and provenance into a standard tabular format. On top of the unified format, we build \textsc{TabGenie}: a toolkit combining web interface, command-line interface and Python bindings for simplifying data visualization and processing. While data visualization helps us to present the contents of individual datasets, a unified format helps with streamlining the process of multi-task training, helping us progress towards \ref{rq:5}. At the end of the section, we present multiple real-world use cases of our framework.


\section{TabGenie Toolkit}
\label{sec:tabgenie}

\begin{refbox}
    This section is based on the paper \emph{\textsc{TabGenie}: A Toolkit for Table-to-Text Generation} \cite{kasnerTabGenieToolkitTabletoText2023}, joint work with Ekaterina Garanina, Ondřej Plátek, and Ondřej Dušek. The work was published as a system demonstration in the Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023). The project was led by the author of the thesis; the other authors helped with minor implementation tasks and paper writing.
\end{refbox}


In this section, we present \textsc{TabGenie} -- a toolkit that enables researchers to explore, preprocess, and analyze a variety of \ac{d2t} generation datasets as tables with associated metadata. The web interface of \textsc{TabGenie} (introduced in \autoref{sec:tabgenie:web}) provides an interactive mode for debugging table-to-text generation models, facilitates side-by-side comparison of generated system outputs, and allows easy exports for manual analysis. \textsc{TabGenie} is also equipped with command line processing tools and Python bindings for unified dataset loading and processing (\autoref{sec:tabgenie:developer}). We release \textsc{TabGenie} as a Python package\footnote{\url{https://pypi.org/project/tabgenie/}} and provide its open-source code and a live demo through Github.\footnote{\url{https://github.com/kasnerz/tabgenie}}

\subsection{Motivation}
\label{sec:tabgenie:motivation}
In \autoref{tab:datasets}, we provided a representative, although not comprehensive, overview of research datasets for \ac{d2t} generation. As the number of datasets keeps growing and research keeps accelerating, researchers need to streamline their interactions with these datasets. However, each dataset comes with a different input format and task description, and the input data may not be easy to access and visualize.  Platforms such as HuggingFace Datasets \cite{lhoest2021datasets} or the GEM benchmark \cite{gehrmannGEMBenchmarkNatural2021}  provide a unified way to access the datasets, but they still leave the majority of the data processing load on the user.

A key component missing from current \ac{d2t} tools is the possibility to visualize input data and generated outputs. Visualization plays an important role in examining and evaluating scientific data \cite{Kehrer2013VisualizationAV} and can help researchers make more informed design choices. A suitable interface can also encourage researchers to step away from unreliable automatic metrics \cite{gehrmannRepairingCrackedFoundation2022} and focus on manual error analysis \cite{van_miltenburg_underreporting_2021,van_miltenburg_barriers_2023}.

Along with that, demands for a \textit{unified input data format} have recently been raised with multi-task training for \aclp{llm} \citep[\textit{inter alia}]{sanh2021multitask,scao2022bloom,ouyang2022TrainingLM}. Some works have used simple data linearization techniques for converting structured data into a textual format to align it with the format used for other tasks \cite{xieUnifiedSKGUnifyingMultiTasking2022,tang2022mvp}. However, they use custom preprocessing code for the linearization, leading to discrepancies between individual works.

To address these gaps, we present \textsc{TabGenie} -- a multi-purpose toolkit for interacting with \ac{d2t} generation datasets. The cornerstone of \textsc{TabGenie} is a \emph{unified data representation}. Each input is represented as a matrix of $m$ columns and $n$ rows consisting of individual cells accompanied with metadata. Building upon this representation, \textsc{TabGenie} provides multiple features for unified workflows with table-to-text datasets, including:
\begin{enumerate}
    \item visualizing individual dataset examples in a tabular format,
    \item interacting with table-to-text generation systems in real time,
    \item comparing generated system outputs,
    \item loading and preprocessing data for downstream tasks,
    \item exporting examples and generating spreadsheets for manual error analysis.
\end{enumerate}

\subsection{Data}
\label{sec:tabgenie:data}

\begin{figure*}[t]
    \centering
    \setlength{\fboxsep}{0pt}\fcolorbox{gray!20}{white}{\includegraphics[width=1.0\textwidth]{img/tabgenie_web.png}}
    \caption[The web interface of \textsc{TabGenie}.]{The web interface of \textsc{TabGenie}. The \emph{left panel} and the \emph{top navigation bar} contain user controls; the \emph{center panel} shows table properties and table content; the \emph{right panel} contains system outputs.}
    \label{fig:tabgenie:web}
\end{figure*}
Input data in \textsc{TabGenie} is in tabular format. We define a \textit{table} as a two-dimensional matrix with $m$ columns and $n$ rows, which together define a grid of $m \times n$ cells. Each cell contains a (possibly empty) text string. A continuous sequence of cells $\{c_{i}, \ldots, c_{i+k}\}$ from the same row or column may be merged, in which case the values of $\{c_{i+1},\ldots,c_{i+k}\}$ are linked to the value of $c_{i}$.  A cell may be optionally marked as a \textit{heading}, which is represented as an additional property of the cell.\footnote{The headings are typically located in the first row or column but may also span multiple rows or columns and may not be adjacent.}

To better accommodate the format of datasets such as ToTTo \cite{parikhToTToControlledTableToText2020} or HiTab \cite{chengHiTabHierarchicalTable2021}, we also allow individual cells to be \textit{highlighted}. Highlighted cells are assumed to be preselected for generating an output description. The tables may be accompanied by an additional set of properties (see the \texttt{properties} block in \autoref{fig:tabgenie:web}),\footnote{The properties usually represent table metadata. An example of such a property is a \textit{``title''} of the table in WikiBio \cite{lebretNeuralTextGeneration2016} or a \textit{``category''} in WebNLG \cite{gardentWebNLGChallengeGenerating2017}.} which we represent as key-value pairs alongside the table. These properties may be used for generating the table description.

\paragraph{Unifying Data Format} Our \ac{d2t} generation datasets contain three high-level input data formats: tables, \acs{rdf}\glsunset{rdf} triples, and key-value pairs. We note that converting the latter two to tabular format requires only minimal changes to the data structure while allowing a unified data representation and visualization. We make a few minor changes to datasets that do not immediately adhere to the tabular format:

\begin{itemize}
    \item For graph-to-text datasets, we format each triple as a row, using three columns labeled \textit{subject}, \textit{predicate}, and \textit{object}.
    \item For key-value datasets, we use a two-column format, where the first column contains the keys and is marked as a heading, and the second column contains the values.
    \item For SportSett:Basketball \cite{thomson2020sportsett},\footnote{A derivative of Rotowire (\citealp{wiseman2017challenges}, see \Cref{sec:datasets,sec:tok-eval}).} we merge its two tables \textit{box score} and \textit{line score} and add appropriate headings where necessary.
\end{itemize}


\paragraph{Datasets}
We include the 16 datasets listed in \autoref{tab:datasets} in \textsc{TabGenie}, covering many subtasks of \ac{d2t} generation. All the datasets are available under a permissive open-source license. To ease the data distribution, we load all the datasets using the Huggingface \texttt{datasets} package \cite{lhoest2021datasets}, which comes equipped with a data downloader. We publicly added to Huggingface \texttt{datasets} 9 out of 16 datasets that were not yet available.\footnote{See \url{https://huggingface.co/datasets?search=kasnerz}.} A custom dataset can be added to \textsc{TabGenie} by simply sub-classing the data loader class and overriding the method for processing individual entries.

\subsection{Web Interface}
\label{sec:tabgenie:web}

\textsc{TabGenie} offers a way to interact with datasets through a \textit{web interface}. The interface features a single-page layout with three panels containing user controls, input data, and system outputs (see \autoref{fig:tabgenie:web}).

\paragraph{Content Exploration} \textsc{TabGenie} renders input data as HTML tables, providing better visualizations than existing data viewers, especially in the case of large and hierarchical tables.\footnote{Compare, e.g., with the ToTTo dataset on Huggingface Datasets where the table is provided in a single field called \textit{``table''}: \url{https://huggingface.co/datasets/totto}.} Users can navigate through individual examples in the dataset sequentially, access an example using its index, or go to a random example. Users can add notes to examples and mark examples as favorites to access later. The interface also shows information about the dataset (such as its description, version, homepage, and license) and provides an option to export individual examples.

\paragraph{Interactive Mode} In the interactive mode, the user can modify the input data and observe how changes influence model outputs. We assume that the model provides access through a simple \acs{api} queried by \textsc{TabGenie}. The user can highlight different cells, edit cell contents, and edit the parameters of the downstream processor.

\paragraph{Pre-generated Outputs} \textsc{TabGenie} also allows to visualize static pre-generated outputs, which are loaded in a JSONL\footnote{\url{https://jsonlines.org}} format from a specified directory. Multiple outputs can be displayed alongside a specific example for comparing outputs from multiple systems.


\subsection{Developer Tools}
\label{sec:tabgenie:developer}
Besides the web interface, \textsc{TabGenie} also provides developer-friendly access through Python bindings and a command-line interface. Both of these interfaces aim to simplify dataset preprocessing in downstream tasks. The key benefit of using \textsc{TabGenie} is that it provides streamlined access to data in a consistent format, removing the need for dataset-specific code for extracting information such as table properties, references, or individual cell values.



\paragraph{Python Bindings} \textsc{TabGenie} can replace custom preprocessing code in Python codebases. With a single unified interface for all the datasets, the \textsc{TabGenie} wrapper class allows to:
\begin{itemize}
    \item load a dataset from the Huggingface Datasets or a local folder,
    \item access individual table cells and their properties,
    \item linearize tables using pre-defined or custom functions,
    \item prepare Huggingface \texttt{Dataset} objects for downstream processing.
\end{itemize}
\textsc{TabGenie} can be installed as a Python package, making the integration simple and intuitive.

\paragraph{Command-line Tools} \textsc{TabGenie} supports several basic commands via command line:
\begin{itemize}
    \item \textbf{Run} The \texttt{tabgenie run} command launches the local web server, mimicking the behavior of \texttt{flask run}.

          \noindent Example usage:
          % \begin{noindent}
\begin{bash}
tabgenie run --port=8890 --host="0.0.0.0"
\end{bash}
% \end{noindent}
    \item \textbf{Export} The \texttt{tabgenie export} command enables batch exporting of the dataset. The supported formats are \texttt{xlsx}, \texttt{html}, \texttt{json}, \texttt{txt}, and \texttt{csv}. Except for \texttt{csv}, table properties can be exported along with the table content.

          \noindent Example usage:
          % \begin{noindent}
\begin{bash}
tabgenie export --dataset "webnlg" \
    --split "dev" \
    --out_dir "export/datasets/webnlg" \
    --export_format "xlsx"
\end{bash}
% \end{noindent}
          \noindent Exports can also be done in the web interface.
    \item \textbf{Spreadsheet} For error analysis, it is common to select $N$ random examples from the dataset along with the system outputs and manually annotate them with error categories. The \texttt{tabgenie sheet} command generates a suitable spreadsheet for this procedure.

          \noindent Example usage:
          % \begin{noindent}
\begin{bash}
tabgenie sheet --dataset "webnlg" \
    --split "dev" \
    --in_file "out-t5-base.jsonl" \
    --out_file "analysis_webnlg.xlsx" \
    --count 50
    \end{bash}
% \end{noindent}
\end{itemize}


\subsection{Implementation}
\label{sec:tabgenie:architecture}

\textsc{TabGenie} runs with Python >=3.8 and requires only a few basic packages as dependencies. It can be installed as a stand-alone \texttt{tabgenie} module from PyPI or from the project repository.

\paragraph{Backend} The web server is based on \texttt{Flask},\footnote{\url{https://pypi.org/project/Flask/}} a popular lightweight Python-based web framework. The server runs locally and can be configured with a YAML\footnote{\url{https://yaml.org}} configuration file. On startup, the server loads the data using the \texttt{datasets}\footnote{\url{https://pypi.org/project/datasets/}} package. To render web pages, the server uses the \texttt{tinyhtml}\footnote{\url{https://pypi.org/project/tinyhtml/}} package and the Jinja\footnote{\url{https://jinja.palletsprojects.com/}} templating language.

\paragraph{Frontend} The web frontend is built on HTML5, CSS, Bootstrap,\footnote{\url{https://getbootstrap.com/}} JavaScript, and jQuery.\footnote{\url{https://jquery.com}} We additionally use the D3.js\footnote{\url{https://d3js.org}} library for visualizing the structure of data in graph-to-text datasets. To keep the project simple, we do not use any other major external libraries.


\subsection{Case Studies}
\label{sec:tabgenie:casestudies}

We present several case studies for using \textsc{TabGenie} in \ac{d2t} generation research. The instructions and code samples for these tasks are available in the project repository.

\paragraph{Table-To-Text Generation} \textsc{TabGenie} can serve for finetuning a sequence-to-sequence language model for table-to-text generation in PyTorch \cite{paszke2019pytorch} using the Huggingface Transformers \cite{wolf2019HuggingFacesTS} framework. In a typical finetuning procedure, the user needs to prepare a \texttt{Dataset} object with tokenized input and output sequences. \textsc{TabGenie} provides a customizable function \texttt{get\_hf\_dataset()}, which linearizes the tables and tokenizes the inputs and references with the provided tokenizer, simplifying preprocessing a dataset to the following:
% \begin{noindent}
\begin{python}
from transformers import AutoTokenizer
import tabgenie as tg

# instantiate a tokenizer
t = AutoTokenizer.from_pretrained(...)
# load the dataset
tg_dataset = tg.load_dataset(dataset_name="totto")
# preprocess the dataset
hf_dataset = tg_dataset.get_hf_dataset(split="train", tokenizer=t)
\end{python}
% \end{noindent}


% For training a single model on multiple datasets in a multi-task learning setting \cite{xieUnifiedSKGUnifyingMultiTasking2022}, the user may preprocess each dataset individually, prepending a dataset-specific task description to each example. The datasets may then be combined using the methods provided by the \texttt{datasets} package.

\paragraph{Interactive Prompting} \textsc{TabGenie} can be used for observing the impact of various prompts during table-to-text generation. The user customizes the provided \texttt{model\_api} pipeline to communicate with the model through an API. The API can communicate either with an external model (using e.g. OpenAI API\footnote{\url{https://openai.com/api/}}), or with a model running locally (using libraries such as FastAPI\footnote{\url{https://fastapi.tiangolo.com}}). The user then interacts with the model through the \textsc{TabGenie} web interface, where they are able to modify prompts or table contents as well as highlight specific cells.

\paragraph{Error Analysis} \textsc{TabGenie} can help with annotating error categories in the outputs of a table-to-text generation model. The user generates system outputs on a test set and saves them in JSONL format. Through the command-line interface, the user will then generate an XLSX file which can be imported into any suitable office software and distributed to annotators for performing error analysis.

\subsection{Discussion}

\paragraph{Limitations} For some \ac{d2t} inputs, the tabular structure may be inappropriate, such as for tree-based structures \cite{balakrishnan2019constrained}, bag-of-words \cite{lin2019commongen}, or multimodal inputs \cite{krishna2017visual}. It is also not well-suited for the heavily nested JSON format, which we explore as the input format in \autoref{sec:quintd}. As the framework targets the research community, its use requires some programming skills (e.g., for integrating the model API).

\paragraph{Extending the Framework} Adding new datasets to \textsc{TabGenie} is straightforward as long as the dataset is convertible to the unified format. Due to deployment issues, \textsc{TabGenie} does not include large synthetic datasets \cite{agarwalKnowledgeGraphBased2021,jinGenWikiDatasetMillion2020}, but these datasets could be added locally.


\section{Conclusion}
We presented a toolkit for unified processing of \ac{d2t} generation datasets. The toolkit enables researchers to gain insights into the datasets by visualizing their contents in a web interface. The toolkit also allows to pre-process datasets in a unified format, facilitating their processing with \acp{lm}. On top of that, the toolkit provides various practical methods such as sending the inputs to a \ac{d2t} generation models via an API or generating error analysis spreadsheets. As such, the framework promotes more informed and principled \ac{d2t} generation research.