
\chapter{Background}
\label{chap:background}

To establish common ground, this chapter explains the \textbf{basic concepts} used throughout the thesis: neural \acp{lm} in \autoref{sec:lms}---all the way from the basic of neural networks and language modeling up to pretrained and large language models---and \ac{d2t} generation in \autoref{sec:d2t}---covering rule-based and neural-based systems, datasets and evaluation methods. We aim to make the explanations self-contained but brief, covering the important concepts but pointing the interested reader to the respective works for details.

Besides explaining the basic concepts, the chapter serves also as an \textbf{overview of the state of the art} in the field. Especially the later subsections (\Cref{sec:plms,sec:llms} for neural \acp{lm} and \Cref{sec:neural-d2t,sec:datasets,sec:evaluation} for \ac{d2t} generation) focus more on describing the datasets and models used for the experiments, summarizing papers referenced throughout the thesis, and providing pointers to the related work.


\section{Neural Language Models}
\label{sec:lms}


\subsection{Neural Networks}
\label{sec:nns}




\subsection{Language Models}
\label{sec:lm-basics}
\subsection{Transformer Architecture}
\label{sec:transformer}
\subsection{Pretrained Language Models}
\label{sec:plms}
\subsection{Large Language Models}
\label{sec:llms}
\section{Data-to-Text Generation}
\label{sec:d2t}
\subsection{Rule-based Approaches}
\label{sec:rule-d2t}
\subsection{Neural Approaches}
\label{sec:neural-d2t}
\subsection{Datasets}
\label{sec:datasets}
\subsection{Evaluation Metrics}
\label{sec:evaluation}