
\chapter{Conclusions}
\label{chap:conclusions}

In this thesis, we set out to explore how to employ neural \acp{lm} in \ac{d2t} generation systems. The issues we were trying to solve---semantic inaccuracies in the generated texts, lack of automatic evaluation metrics, heterogeneous input data format, and unknown scope of \acp{lm} abilities---are as pressing as ever, despite the increase in \ac{lm} capabilities over the past few years. That is not to say that there has not been any progress: the opposite is evidenced by numerous works introduced in \autoref{chap:background} (along with many others we did not get a chance to mention).


Hopefully, we also contributed to the progress with our findings, including:
\begin{itemize}
    \item Our approaches for efficient application of \acp{plm} in \ac{d2t} generation systems (\autoref{chap:low-res}),
    \item Our \acp{plm}-based automatic metrics for evaluating semantic accuracy of generated texts (\autoref{chap:evaluation}),
    \item Our toolkit for unified processing and visualization of existing \ac{d2t} generation benchmarks (\autoref{chap:tabgenie}),
    \item Our custom benchmarks for analyzing generalization abilities of neural \acp{lm} to novel domains and formats (\autoref{chap:investigating}).
\end{itemize}

At this point, we should take a step back and revisit the basic questions. Are the problems we are solving in \ac{d2t} generation still relevant? Do we want to continue integrating \acp{lm} in \ac{d2t} generation systems? And is there value in developing specialized approaches, or are all the problems of the field going to be solved by using ever larger models?

A good starting point to answer these questions is realizing that \acp{lm} are here to stay. The ongoing proliferation of \acp{lm} in \ac{nlp} makes it hard to imagine an \ac{nlp} subfield left intact by impact of \acp{lm}. And there is a reason for that: with \acp{lm}, certain things unimaginable during previous decades---such as fine-grained steering of a system using natural language instructions---are now becoming possible. We can expect that \ac{d2t} \emph{without \acp{lm}}, to put it bluntly, would soon start to feel awkward. People are already becoming used to consuming fluent texts and seamlessly interacting with language generation systems, aspects that are hard to replace with non-\ac{lm} systems. As we stated the introduction, \ac{d2t} generation is primarily about simplifying interactions of end users with large amounts of structured data. If \ac{d2t} generation is to stay relevant, these aspects cannot be neglected.

At the same time, the users (hopefully, along with us researchers) are becoming aware of limitations of \ac{lm}-based systems. Even the most powerful \acp{lm} nowadays cannot reliably count words in a sentence, multiply larger numbers, or recognize unplausible requests. Most probably, these issues will not be fully solved with further scaling or minor architectural improvements. We therefore need to tread carefully when integrating \acp{lm} in \ac{d2t} generation systems: a system relying too heavily on \acp{lm} may not be ever able to guarantee outputs accurate enough for day-to-day usage, let alone for sensitive applications.

It would be, however, counter-productive to dismiss \acp{lm} by likening them to a ``black box'', picking on their unpredictable behavior. It is better to acknowledge that even the \emph{black boxes} are still \emph{boxes}: components that can be embedded in a larger system. As we have repeatedly showed throughout the thesis, such a component can be helpful when used wisely. We can, for example, over-generate \ac{lm} outputs and select only the relevant ones (\autoref{sec:iterative}), train the \ac{lm} in a way that its outputs are more predictable (\autoref{sec:pipeline}), or simply make use of the state-of-the-art performance of \acp{lm} on tasks such as natural language inference or text classification (\Cref{sec:sem-acc,sec:tok-eval}).

Looking at recent developments, we only scratched the surface of what is possible. The general idea of connecting \acp{lm} to data preprocessors, filters, re-rankers, Python interpreters and other tools seems to be a surefire way towards building more powerful systems for interacting with structured data. And along with that come other ideas from the general research of \acp{llm} for \ac{nlp}: chain-of-thought prompting, retrieval-augmented generation, ecosystem of specialized \acp{lm}. Taken all together, there currently seems to be no bound on improvements.

It is interesting to notice, that in these systems, \ac{d2t} generation itself is dissolving and becoming more transparent to both users and researchers. We can envisage powerful data analytics tools combining components for data mining, natural language understanding, text-to-SQL, table question answering, many of which may be tackled by the same component.

Evaluating such systems will, admittedly, get more difficult. Iterating over improving \acs{bleu} is not a thing driving a research forward even nowadays. Recent years have witnessed the decline of classical evaluation metrics; future years will perhaps witness the decline of classical benchmarks. Similarly as we , we will need to focus on extrinsic evaluation and ecological validity.
