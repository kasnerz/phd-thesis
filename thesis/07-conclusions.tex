
\chapter{Conclusions}
\label{chap:conclusions}

We set out to explore how to use \acp{lm} to improve the robustness and fluency of \ac{d2t} generation systems. The issues we had to deal with---semantic inaccuracies of generated texts, lack of automatic evaluation metrics, heterogeneous data formats, and unknown scope of \acp{lm} abilities---are as pressing as ever, despite the increase in \ac{lm} capabilities over the past few years. That is not to say that there has not been any progress: the opposite is evidenced by numerous works introduced in \autoref{chap:background} and others we did not get the chance to mention.

We hope to have also contributed to the progress with the answers to our research questions outlined in \autoref{sec:rq}, including:
\begin{itemize}
    \item \textbf{\ref{rq:1}}: Our finding that simple \ac{lm}-based approaches can be used for generating fluent outputs from structured data (\Cref{sec:finetuning,sec:quintd}),
    \item \textbf{\ref{rq:2}}: Our finding that preprocessing the data with templates and rule-based systems can help downstream \ac{lm} components (\Cref{sec:iterative,sec:pipeline,sec:sem-acc,sec:tok-eval}),
    \item \textbf{\ref{rq:3}}: Our finding that constraining \ac{lm} to improving text quality helps to improve the semantic accuracy of the system outputs (\Cref{sec:iterative,sec:pipeline}),
    \item \textbf{\ref{rq:4}}: Our finding that \acp{lm} can be also used for automatic metrics for evaluating semantic accuracy (\Cref{sec:sem-acc,sec:tok-eval}),
    \item \textbf{\ref{rq:5}}: Our finding that the best way to leverage \ac{lm} pretraining is to use standardized and understandable input formats (\Cref{sec:tabgenie,sec:rel2text,sec:quintd}).
\end{itemize}

At this point, we are well-equipped to also discuss a few meta-questions. Are we solving the right problems in \ac{d2t} generation? Do we want to continue integrating \acp{lm} in \ac{d2t} generation systems? And is there value in developing specialized approaches, or are all the problems going to be solved by using ever larger models?

A good starting point to answering these questions is realizing that \aclp{lm} (and \acsp{llm}\glsunset{llm} in particular) are here to stay. The ongoing proliferation of \acp{llm} in \acl{nlp} \cite{min2023recent,zhao2023survey,naveed2024comprehensive} makes it hard to imagine a subfield that would be left intact by their impact. There is a solid reason for that: with \acp{llm}, certain things unimaginable during previous decades---such as fine-grained steering of a system using natural language instructions---are now becoming possible. We can expect that \ac{d2t} \emph{without \acp{llm}} would, to put it bluntly, soon start to feel awkward. People are already becoming used to consuming fluent texts and seamlessly interacting with language generation systems, aspects that are hard to replace with non-\ac{llm} systems. As we stated in the introduction, \ac{d2t} generation is primarily about simplifying interactions for end users, so these aspects cannot be neglected if \ac{d2t} research is to stay relevant.

At the same time, users are (hopefully, along with us researchers) becoming aware of the limitations of \ac{lm}-based systems. Even the most powerful \acp{lm} nowadays cannot reliably perform symbolic tasks such as basic arithmetic operations \cite{qian2023limitations}, understand reflexivity of relations between entities \cite{berglund2024the}, or recognize unanswerable or unknowable questions \cite{yin2023large}. All of these issues are tied to \ac{d2t} generation: for example, understanding the scope of relations (and recognizing the ambiguous ones) is crucial for the correct verbalization of knowledge graphs, as we discussed in \autoref{sec:rel2text}. It is reasonable to expect that these issues will not be fully solved with further scaling of \acp{llm} or minor architectural improvements. We therefore need to tread carefully when integrating \acp{lm} into \ac{d2t} generation systems: a system relying too heavily on \acp{lm} may not be ever able to guarantee outputs accurate enough for day-to-day usage, let alone for sensitive applications.

It would be, however, counter-productive to dismiss \acp{lm} by likening them to a ``black box'', picking on their unpredictable behavior. It is better to acknowledge that even the \emph{black boxes} are still \emph{boxes}: components that can be embedded in a larger system. As we repeatedly showed throughout the thesis, such a component can be helpful when used wisely. We can, for example, over-generate \ac{lm} outputs and select only the relevant ones (\autoref{sec:iterative}) or train the \ac{lm} in a way that its outputs are more predictable (\autoref{sec:pipeline}). We can also build our system around the tasks on which \acp{lm} achieve state-of-the-art performance, such as natural language inference (\autoref{sec:sem-acc}) or text classification (\autoref{sec:tok-eval}).

Looking at recent developments, we only scratched the surface of what is possible. Even now, we can go beyond the lexicalization and surface realization steps---which were the primary focus of this thesis---by connecting \acp{lm} to tools such as a Python interpreter or an SQL engine, enabling \acp{lm} to perform content selection as well \cite{cao-etal-2023-api,jiang-etal-2023-structgpt,gemmell2023generate}. We can imagine that by combining code execution with approaches such as chain-of-thought prompting and its advanced variants \cite{weiChainThoughtPrompting2022,chu2023survey}, the systems will be able to automatically perform logical operations over the data to derive interesting insights \cite{zhao-etal-2023-qtsumm,chenLogicalNaturalLanguage2020,chenLogic2TextHighFidelityNatural2020}. Soon, we may think of literal data transcription or shallow data summarization the way we think about, for example, word-for-word translation: as an approach that is too basic to even consider using. \ac{lm}-powered systems could thus get us closer to presenting useful insights from large-scale structured data, the ultimate purpose of \ac{d2t} generation.

As the systems get better at handling multiple \ac{nlp} tasks in a unified way, the role of individual tasks---such as \ac{d2t} generation---could become somewhat less important. A single \ac{lm}-based component could jointly tackle all the tasks that are currently thought of as stand-alone: natural language understanding, text-to-SQL, data mining, question answering, or data-to-text generation \cite{schopf-etal-2023-exploring,chen2024multi}. Rather than in the tasks themselves, the researchers would then specialize in auxiliary tools used on top of the \acp{lm} such as approaches for steering the generation process, output quality assurance, or personalization \cite{zhang2023survey,chen2023personalization}.


Evaluating future systems may get more difficult. The first step we need to focus on is making the current evaluation measures reflect actual system improvements \cite{gehrmannRepairingCrackedFoundation2022,van_miltenburg_barriers_2023}.  As we discussed in \autoref{sec:quintd}, this can mean moving away from traditional benchmarks, that can get saturated \cite{kiela-etal-2021-dynabench,raji2021ai}, or even included in the \ac{llm} training data \cite{balloccu2024leak}. In the long run, we should also focus on the ecological validity of the systems we are developing \cite{reiter2020ecological}. To achieve that, we should focus more on extrinsic evaluation, i.e., evaluating the system as a whole instead of its individual components (cf. \citealp{reiter2003lessons,di-eugenio-etal-2002-diag}, see also \autoref{sec:evaluation}). These measures are harder to iterate on but give us a better picture of the real-world impact of the systems we are building.

A final recommendation, that perhaps should have come a bit sooner: \emph{look in the data and try to perform the task yourselves first}. As much as we introduced the data as the language of computers, its content and structure can always be traced down to human-made inputs. Our experiments---such as the ones in \Cref{sec:tabgenie,sec:rel2text}---made it clear to us that the inputs are often messy, incomplete, and hard to understand. In these cases, making the systems present the data in understandable form is equivalent to translating gibberish from one language to another. Until the computers can reliably detect and fix our errors, we need to do the legwork and fix it ourselves. In other words, we need to keep on learning the language of the data we are producing.