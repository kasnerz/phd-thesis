% Current systems for data-to-text generation can guarantee high levels of semantic accuracy, but their fluency and adaptability to new domains remains limited. In this thesis, we explore how to improve these aspects with neural components. First, we introduce data-efficient approaches for data-to-text generation that can maintain high levels of semantic accuracy, using pretrained language models as building blocks. We also introduce two model-based automatic evaluation metrics for assessing the semantic accuracy. Turning to data-to-text generation datasets, we unify existing datasets in a common format, enabling their efficient visualization and processing. Finally, using custom datasets, we investigate generalization abilities of neural language models: the ability to verbalize unseen relations in knowledge graphs and the ability to generate accurate texts from standard data formats. We conclude that while data-to-text generation with neural language models remains a delicate endeavor, neural components are the preferred approach for improving fluency of the output texts. Neural language models also make the systems more easily adaptable to new domains and input formats. For the future research, we emphasize the need for proper benchmarking with suitable evaluation metrics on real-world use-cases.


Data-to-text generation systems need to produce texts with high levels of semantic accuracy. Rule-based systems can guarantee this aspect, but their fluency and adaptability to new domains remain limited. Meanwhile, neural language models can easily generate fluent texts and adapt to new domains but are notoriously prone to producing inaccurate outputs. In this thesis, we explore how to efficiently employ neural components in data-to-text generation systems to get the best of both worlds. We focus on approaches based on pretrained transformer language models. Primarily, the models serve us as building blocks for data-efficient and controllable data-to-text generation systems. Along with that, we introduce novel model-based evaluation metrics and a toolkit for preprocessing and visualizing data-to-text generation datasets. We also analyze the models in specific scenarios, including describing relations in knowledge graphs and data-to-text generation with large language models. We conclude that while employing neural language models in data-to-text generation remains a delicate endeavor, neural components can improve the fluency of the output texts and make the systems adaptable to new domains and input formats. For future research, we emphasize the need for proper benchmarking with suitable evaluation metrics on real-world use cases.