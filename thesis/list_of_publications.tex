\chapter*{List of Publications}

\phantom{\nobibliography*{references}}

% -----------------------------------------------------------------------------

\noindent\bibentry{kasnerTrainHardFinetune2020}
\begin{itemize}[noitemsep,topsep=0pt]

    \item Our submission for the WebNLG+ shared task.
    \item The data-to-text generation system based on the finetuned mBART model (\autoref{sec:finetuning}).
    \item Citations (without self-citations): 9
\end{itemize}\vspace{.5\baselineskip}

% -----------------------------------------------------------------------------
\noindent\bibentry{kasnerDatatoTextGenerationIterative2020}
\begin{itemize}[noitemsep,topsep=0pt]
    \item The data-to-text generation system based on iterative text editing (\autoref{sec:iterative}).
    \item Citations (without self-citations): 16

\end{itemize}\vspace{.5\baselineskip}

% -----------------------------------------------------------------------------
\noindent\bibentry{kasner2022neural}
\begin{itemize}[noitemsep,topsep=0pt]
    \item The data-to-text generation system based on a pipeline of neural modules (\autoref{sec:pipeline}).
    \item Citations (without self-citations): 21

\end{itemize}\vspace{.5\baselineskip}

% -----------------------------------------------------------------------------
\noindent\bibentry{dusekEvaluatingSemanticAccuracy2020}
\begin{itemize}[noitemsep,topsep=0pt]

    \item The metric for detecting omissions and halluccination in generated texts (\autoref{sec:tok-eval}).
    \item Best short paper at INLG 2020.
    \item Citations (without self-citations): 46

\end{itemize}\vspace{.5\baselineskip}


% -----------------------------------------------------------------------------
\noindent\bibentry{kasnerTextinContextTokenLevelError2021}
\begin{itemize}[noitemsep,topsep=0pt]
    \item Our submission to the shared task Evaluating Accuracy in Generated Texts.
    \item The metric for token-level error detection in generated texts (\autoref{sec:tok-eval})
    \item Citations (without self-citations): 6

\end{itemize}\vspace{.5\baselineskip}


% -----------------------------------------------------------------------------
\noindent\bibentry{kasnerTabGenieToolkitTabletoText2023}
\begin{itemize}[noitemsep,topsep=0pt]

    \item The toolkit for processing and visualization of data-to-text generation datasets (\autoref{sec:tabgenie}).
    \item Citations (without self-citations): 2

\end{itemize}\vspace{.5\baselineskip}


% -----------------------------------------------------------------------------
\noindent\bibentry{kasnerMindLabelsDescribing2022}
\begin{itemize}[noitemsep,topsep=0pt]

    \item Verbalizing new relations in a knowledge graph with pretrained language models (\autoref{sec:rel2text}).
    \item Citations (without self-citations): 4

\end{itemize}\vspace{.5\baselineskip}


% -----------------------------------------------------------------------------
\noindent\bibentry{kasnerReferenceBasedMetricsAnalyzing2024}
\begin{itemize}[noitemsep,topsep=0pt]

    \item The analysis of data-to-text generation with open large language models (\autoref{sec:quintd}).
    \item Citations (without self-citations): 2

\end{itemize}\vspace{.5\baselineskip}

\vfill

\noindent Only publications relevant to this thesis are included. The number of
citations was computed using Semantic Scholar. Total number of citations of
publications related to the topic of the thesis (without self-citations):
{\large TODO} % (by the thesis submission on November 17, 2021).
