Od systémů pro generování textu z dat očekáváme texty vysokou úrovní přesnosti vzhledem k vstupním datům. Pravidlové systémy mohou tento aspekt zaručit, ale zaostávají v plynulosti výstupů a přizpůsobitelnosti novým doménám. Naopak neuronové jazykové modely zvládají snadno generovat plynulé texty a přizpůsobovat se novým doménám, ale jsou notoricky náchylné k produkci nepřesných výstupů. V této práci zkoumáme, jak efektivně zakomponovat do systémů pro generování textu z dat neuronové modely tak, abychom propojili výhody obou typů systémů. Naše přístupy zakládáme na předtrénovaných jazykových modelech architektury transformer. Tyto modely primárně používáme jako stavební bloky, se kterými mohou být systémy pro generování textu robustní a efektivně využívat trénovací data. Spolu s tím představujeme nové evaluační metriky pro odhalování chyb ve výstupech, založené na předtrénovaných modelech, a sadu nástrojů pro předzpracování a vizualizaci datasetů pro generování textu z dat. Analyzujeme také chování předtrénovaných a velkých jazykových modelů ve specifických případech jako je popis jednotlivých relaci ve znalostních grafech a generování textů ze standardních datových formátů. Z~našich experimentů vyplývá, že ačkoli k použití neuronových jazykových modelů při generování textu z dat je potřeba přistupovat s rozmyslem, neuronové komponenty mohou zlepšit plynulost výstupních textů a umožnit přizpůsobení systémů novým doménám a vstupním formátům. Přesnost výstupů přitom může zůstat vysoká, pokud se modely používají pro konkrétní, přesně definované dílčí úkoly pro zlepšení kvality textu. Pro budoucí výzkum zdůrazňujeme potřebu smysluplného vyhodnocování systémů pomocí vhodných evaluačních metrik na reálných případech použití.